[2020-02-27 08:00:48,839] INFO Reading configuration from: c:\kafka_\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-02-27 08:00:48,857] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-27 08:00:48,858] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-27 08:00:48,859] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-27 08:00:48,860] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-02-27 08:00:48,965] INFO Reading configuration from: c:\kafka_\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-02-27 08:00:48,968] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-02-27 08:00:49,003] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,004] INFO Server environment:host.name=MTNB311.mitrais.com (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,005] INFO Server environment:java.version=1.8.0_31 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,005] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,006] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_31\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,006] INFO Server environment:java.class.path=.;c:\java;c:\apache-tomcat-9.0.14\lib\activation.jar;c:\apache-tomcat-9.0.14\lib\commons-email-1.4.jar;c:\apache-tomcat-9.0.14\lib\commons-fileupload-1.0.jar;c:\apache-tomcat-9.0.14\lib\itext-4.2.0.jar;c:\apache-tomcat-9.0.14\lib\jcommon-1.0.23.jar;c:\apache-tomcat-9.0.14\lib\jfreechart-1.0.19.jar;c:\apache-tomcat-9.0.14\lib\json-1.1.jar;c:\apache-tomcat-9.0.14\lib\mail.jar;c:\apache-tomcat-9.0.14\lib\mysql-connector-java-3.0.10-stable-bin.jar;c:\apache-tomcat-9.0.14\lib\servlet-api.jar;c:\apache-tomcat-9.0.14\webapps\infocare\WEB-INF\classes;;C:\kafka_\libs\activation-1.1.1.jar;C:\kafka_\libs\aopalliance-repackaged-2.5.0.jar;C:\kafka_\libs\argparse4j-0.7.0.jar;C:\kafka_\libs\audience-annotations-0.5.0.jar;C:\kafka_\libs\commons-lang3-3.8.1.jar;C:\kafka_\libs\connect-api-2.3.0.jar;C:\kafka_\libs\connect-basic-auth-extension-2.3.0.jar;C:\kafka_\libs\connect-file-2.3.0.jar;C:\kafka_\libs\connect-json-2.3.0.jar;C:\kafka_\libs\connect-runtime-2.3.0.jar;C:\kafka_\libs\connect-transforms-2.3.0.jar;C:\kafka_\libs\guava-20.0.jar;C:\kafka_\libs\hk2-api-2.5.0.jar;C:\kafka_\libs\hk2-locator-2.5.0.jar;C:\kafka_\libs\hk2-utils-2.5.0.jar;C:\kafka_\libs\jackson-annotations-2.9.9.jar;C:\kafka_\libs\jackson-core-2.9.9.jar;C:\kafka_\libs\jackson-databind-2.9.9.jar;C:\kafka_\libs\jackson-dataformat-csv-2.9.9.jar;C:\kafka_\libs\jackson-datatype-jdk8-2.9.9.jar;C:\kafka_\libs\jackson-jaxrs-base-2.9.9.jar;C:\kafka_\libs\jackson-jaxrs-json-provider-2.9.9.jar;C:\kafka_\libs\jackson-module-jaxb-annotations-2.9.9.jar;C:\kafka_\libs\jackson-module-paranamer-2.9.9.jar;C:\kafka_\libs\jackson-module-scala_2.12-2.9.9.jar;C:\kafka_\libs\jakarta.annotation-api-1.3.4.jar;C:\kafka_\libs\jakarta.inject-2.5.0.jar;C:\kafka_\libs\jakarta.ws.rs-api-2.1.5.jar;C:\kafka_\libs\javassist-3.22.0-CR2.jar;C:\kafka_\libs\javax.servlet-api-3.1.0.jar;C:\kafka_\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_\libs\jaxb-api-2.3.0.jar;C:\kafka_\libs\jersey-client-2.28.jar;C:\kafka_\libs\jersey-common-2.28.jar;C:\kafka_\libs\jersey-container-servlet-2.28.jar;C:\kafka_\libs\jersey-container-servlet-core-2.28.jar;C:\kafka_\libs\jersey-hk2-2.28.jar;C:\kafka_\libs\jersey-media-jaxb-2.28.jar;C:\kafka_\libs\jersey-server-2.28.jar;C:\kafka_\libs\jetty-client-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-continuation-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-http-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-io-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-security-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-server-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-servlet-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-servlets-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-util-9.4.18.v20190429.jar;C:\kafka_\libs\jopt-simple-5.0.4.jar;C:\kafka_\libs\jsr305-3.0.2.jar;C:\kafka_\libs\kafka-clients-2.3.0.jar;C:\kafka_\libs\kafka-log4j-appender-2.3.0.jar;C:\kafka_\libs\kafka-streams-2.3.0.jar;C:\kafka_\libs\kafka-streams-examples-2.3.0.jar;C:\kafka_\libs\kafka-streams-scala_2.12-2.3.0.jar;C:\kafka_\libs\kafka-streams-test-utils-2.3.0.jar;C:\kafka_\libs\kafka-tools-2.3.0.jar;C:\kafka_\libs\kafka_2.12-2.3.0-javadoc.jar;C:\kafka_\libs\kafka_2.12-2.3.0-javadoc.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-scaladoc.jar;C:\kafka_\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-sources.jar;C:\kafka_\libs\kafka_2.12-2.3.0-sources.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-test-sources.jar;C:\kafka_\libs\kafka_2.12-2.3.0-test-sources.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-test.jar;C:\kafka_\libs\kafka_2.12-2.3.0-test.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0.jar;C:\kafka_\libs\kafka_2.12-2.3.0.jar.asc;C:\kafka_\libs\log4j-1.2.17.jar;C:\kafka_\libs\lz4-java-1.6.0.jar;C:\kafka_\libs\maven-artifact-3.6.1.jar;C:\kafka_\libs\metrics-core-2.2.0.jar;C:\kafka_\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_\libs\paranamer-2.8.jar;C:\kafka_\libs\plexus-utils-3.2.0.jar;C:\kafka_\libs\reflections-0.9.11.jar;C:\kafka_\libs\rocksdbjni-5.18.3.jar;C:\kafka_\libs\scala-library-2.12.8.jar;C:\kafka_\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_\libs\scala-reflect-2.12.8.jar;C:\kafka_\libs\slf4j-api-1.7.26.jar;C:\kafka_\libs\slf4j-log4j12-1.7.26.jar;C:\kafka_\libs\snappy-java-1.1.7.3.jar;C:\kafka_\libs\spotbugs-annotations-3.1.9.jar;C:\kafka_\libs\validation-api-2.0.1.Final.jar;C:\kafka_\libs\zkclient-0.11.jar;C:\kafka_\libs\zookeeper-3.4.14.jar;C:\kafka_\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,009] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_31\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Intel\iCLS Client\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Skype\Phone\;C:\Program Files (x86)\Microsoft SQL Server\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\apache-maven-3.6.0\bin;C:\Program Files\Git\cmd;C:\Program Files (x86)\MySQL\MySQL Fabric 1.5.3 & MySQL Utilities 1.5.3 1.5\;C:\Program Files (x86)\MySQL\MySQL Fabric 1.5.3 & MySQL Utilities 1.5.3 1.5\Doctrine extensions for PHP\;C:\Program Files (x86)\WinSCP\;C:\Users\Syarif_H657\Downloads\gradle-5.2.1\bin;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\MongoDB\Server\4.0\bin;C:\Go\bin;C:\Program Files\Java\jdk1.8.0_31\bin;;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\nodejs\;C:\Users\Syarif_H657\AppData\Local\Programs\Python\Python37-32\Scripts\;C:\Users\Syarif_H657\AppData\Local\Programs\Python\Python37-32\;C:\Users\Syarif_H657\AppData\Local\Microsoft\WindowsApps;C:\Program Files\JetBrains\IntelliJ IDEA 2018.3.4\bin;C:\Program Files\JetBrains\WebStorm 2018.3.5\bin;C:\Users\Syarif_H657\AppData\Local\Yarn\bin;C:\Program Files\JetBrains\GoLand 2019.1.3\bin;C:\Users\Syarif_H657\go\bin;C:\Users\Syarif_H657\AppData\Local\GitHubDesktop\bin;C:\Users\Syarif_H657\AppData\Local\Microsoft\WindowsApps;;f:\Atlassian\atlassian-plugin-sdk-8.0.16\bin;C:\Program Files\Haulmont\CUBA Studio 2019.1\bin;;C:\Users\Syarif_H657\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,012] INFO Server environment:java.io.tmpdir=C:\Users\SYARIF~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,014] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,023] INFO Server environment:os.name=Windows 8.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,024] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,025] INFO Server environment:os.version=6.3 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,026] INFO Server environment:user.name=Syarif_H657 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,027] INFO Server environment:user.home=C:\Users\Syarif_H657 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,028] INFO Server environment:user.dir=C:\kafka_\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,056] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,058] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,060] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:49,188] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-02-27 08:00:49,201] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-27 08:00:56,309] INFO Expiring session 0x10041e627f30001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:00:56,321] INFO Processed session termination for sessionid: 0x10041e627f30001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 08:00:56,322] INFO Creating new log file: log.e4 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-02-27 08:02:25,875] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-02-27 08:02:27,595] INFO starting (kafka.server.KafkaServer)
[2020-02-27 08:02:27,600] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-02-27 08:02:27,686] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-02-27 08:02:27,706] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,711] INFO Client environment:host.name=MTNB311.mitrais.com (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,711] INFO Client environment:java.version=1.8.0_31 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,711] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,711] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_31\jre (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,711] INFO Client environment:java.class.path=.;c:\java;c:\apache-tomcat-9.0.14\lib\activation.jar;c:\apache-tomcat-9.0.14\lib\commons-email-1.4.jar;c:\apache-tomcat-9.0.14\lib\commons-fileupload-1.0.jar;c:\apache-tomcat-9.0.14\lib\itext-4.2.0.jar;c:\apache-tomcat-9.0.14\lib\jcommon-1.0.23.jar;c:\apache-tomcat-9.0.14\lib\jfreechart-1.0.19.jar;c:\apache-tomcat-9.0.14\lib\json-1.1.jar;c:\apache-tomcat-9.0.14\lib\mail.jar;c:\apache-tomcat-9.0.14\lib\mysql-connector-java-3.0.10-stable-bin.jar;c:\apache-tomcat-9.0.14\lib\servlet-api.jar;c:\apache-tomcat-9.0.14\webapps\infocare\WEB-INF\classes;;C:\kafka_\libs\activation-1.1.1.jar;C:\kafka_\libs\aopalliance-repackaged-2.5.0.jar;C:\kafka_\libs\argparse4j-0.7.0.jar;C:\kafka_\libs\audience-annotations-0.5.0.jar;C:\kafka_\libs\commons-lang3-3.8.1.jar;C:\kafka_\libs\connect-api-2.3.0.jar;C:\kafka_\libs\connect-basic-auth-extension-2.3.0.jar;C:\kafka_\libs\connect-file-2.3.0.jar;C:\kafka_\libs\connect-json-2.3.0.jar;C:\kafka_\libs\connect-runtime-2.3.0.jar;C:\kafka_\libs\connect-transforms-2.3.0.jar;C:\kafka_\libs\guava-20.0.jar;C:\kafka_\libs\hk2-api-2.5.0.jar;C:\kafka_\libs\hk2-locator-2.5.0.jar;C:\kafka_\libs\hk2-utils-2.5.0.jar;C:\kafka_\libs\jackson-annotations-2.9.9.jar;C:\kafka_\libs\jackson-core-2.9.9.jar;C:\kafka_\libs\jackson-databind-2.9.9.jar;C:\kafka_\libs\jackson-dataformat-csv-2.9.9.jar;C:\kafka_\libs\jackson-datatype-jdk8-2.9.9.jar;C:\kafka_\libs\jackson-jaxrs-base-2.9.9.jar;C:\kafka_\libs\jackson-jaxrs-json-provider-2.9.9.jar;C:\kafka_\libs\jackson-module-jaxb-annotations-2.9.9.jar;C:\kafka_\libs\jackson-module-paranamer-2.9.9.jar;C:\kafka_\libs\jackson-module-scala_2.12-2.9.9.jar;C:\kafka_\libs\jakarta.annotation-api-1.3.4.jar;C:\kafka_\libs\jakarta.inject-2.5.0.jar;C:\kafka_\libs\jakarta.ws.rs-api-2.1.5.jar;C:\kafka_\libs\javassist-3.22.0-CR2.jar;C:\kafka_\libs\javax.servlet-api-3.1.0.jar;C:\kafka_\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_\libs\jaxb-api-2.3.0.jar;C:\kafka_\libs\jersey-client-2.28.jar;C:\kafka_\libs\jersey-common-2.28.jar;C:\kafka_\libs\jersey-container-servlet-2.28.jar;C:\kafka_\libs\jersey-container-servlet-core-2.28.jar;C:\kafka_\libs\jersey-hk2-2.28.jar;C:\kafka_\libs\jersey-media-jaxb-2.28.jar;C:\kafka_\libs\jersey-server-2.28.jar;C:\kafka_\libs\jetty-client-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-continuation-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-http-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-io-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-security-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-server-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-servlet-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-servlets-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-util-9.4.18.v20190429.jar;C:\kafka_\libs\jopt-simple-5.0.4.jar;C:\kafka_\libs\jsr305-3.0.2.jar;C:\kafka_\libs\kafka-clients-2.3.0.jar;C:\kafka_\libs\kafka-log4j-appender-2.3.0.jar;C:\kafka_\libs\kafka-streams-2.3.0.jar;C:\kafka_\libs\kafka-streams-examples-2.3.0.jar;C:\kafka_\libs\kafka-streams-scala_2.12-2.3.0.jar;C:\kafka_\libs\kafka-streams-test-utils-2.3.0.jar;C:\kafka_\libs\kafka-tools-2.3.0.jar;C:\kafka_\libs\kafka_2.12-2.3.0-javadoc.jar;C:\kafka_\libs\kafka_2.12-2.3.0-javadoc.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-scaladoc.jar;C:\kafka_\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-sources.jar;C:\kafka_\libs\kafka_2.12-2.3.0-sources.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-test-sources.jar;C:\kafka_\libs\kafka_2.12-2.3.0-test-sources.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-test.jar;C:\kafka_\libs\kafka_2.12-2.3.0-test.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0.jar;C:\kafka_\libs\kafka_2.12-2.3.0.jar.asc;C:\kafka_\libs\log4j-1.2.17.jar;C:\kafka_\libs\lz4-java-1.6.0.jar;C:\kafka_\libs\maven-artifact-3.6.1.jar;C:\kafka_\libs\metrics-core-2.2.0.jar;C:\kafka_\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_\libs\paranamer-2.8.jar;C:\kafka_\libs\plexus-utils-3.2.0.jar;C:\kafka_\libs\reflections-0.9.11.jar;C:\kafka_\libs\rocksdbjni-5.18.3.jar;C:\kafka_\libs\scala-library-2.12.8.jar;C:\kafka_\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_\libs\scala-reflect-2.12.8.jar;C:\kafka_\libs\slf4j-api-1.7.26.jar;C:\kafka_\libs\slf4j-log4j12-1.7.26.jar;C:\kafka_\libs\snappy-java-1.1.7.3.jar;C:\kafka_\libs\spotbugs-annotations-3.1.9.jar;C:\kafka_\libs\validation-api-2.0.1.Final.jar;C:\kafka_\libs\zkclient-0.11.jar;C:\kafka_\libs\zookeeper-3.4.14.jar;C:\kafka_\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,711] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_31\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Intel\iCLS Client\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Skype\Phone\;C:\Program Files (x86)\Microsoft SQL Server\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\apache-maven-3.6.0\bin;C:\Program Files\Git\cmd;C:\Program Files (x86)\MySQL\MySQL Fabric 1.5.3 & MySQL Utilities 1.5.3 1.5\;C:\Program Files (x86)\MySQL\MySQL Fabric 1.5.3 & MySQL Utilities 1.5.3 1.5\Doctrine extensions for PHP\;C:\Program Files (x86)\WinSCP\;C:\Users\Syarif_H657\Downloads\gradle-5.2.1\bin;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\MongoDB\Server\4.0\bin;C:\Go\bin;C:\Program Files\Java\jdk1.8.0_31\bin;;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\nodejs\;C:\Users\Syarif_H657\AppData\Local\Programs\Python\Python37-32\Scripts\;C:\Users\Syarif_H657\AppData\Local\Programs\Python\Python37-32\;C:\Users\Syarif_H657\AppData\Local\Microsoft\WindowsApps;C:\Program Files\JetBrains\IntelliJ IDEA 2018.3.4\bin;C:\Program Files\JetBrains\WebStorm 2018.3.5\bin;C:\Users\Syarif_H657\AppData\Local\Yarn\bin;C:\Program Files\JetBrains\GoLand 2019.1.3\bin;C:\Users\Syarif_H657\go\bin;C:\Users\Syarif_H657\AppData\Local\GitHubDesktop\bin;C:\Users\Syarif_H657\AppData\Local\Microsoft\WindowsApps;;f:\Atlassian\atlassian-plugin-sdk-8.0.16\bin;C:\Program Files\Haulmont\CUBA Studio 2019.1\bin;;C:\Users\Syarif_H657\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,716] INFO Client environment:java.io.tmpdir=C:\Users\SYARIF~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,716] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,719] INFO Client environment:os.name=Windows 8.1 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,719] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,721] INFO Client environment:os.version=6.3 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,721] INFO Client environment:user.name=Syarif_H657 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,726] INFO Client environment:user.home=C:\Users\Syarif_H657 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,726] INFO Client environment:user.dir=C:\kafka_\bin\windows (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,731] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2e4b8173 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 08:02:27,794] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-27 08:02:27,801] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-02-27 08:02:27,806] INFO Accepted socket connection from /127.0.0.1:62337 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-27 08:02:27,806] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-02-27 08:02:27,823] INFO Client attempting to establish new session at /127.0.0.1:62337 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:02:27,832] INFO Established session 0x1004716d6d10000 with negotiated timeout 6000 for client /127.0.0.1:62337 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:02:27,838] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1004716d6d10000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-02-27 08:02:27,850] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-27 08:02:27,995] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10000 type:create cxid:0x1 zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 08:02:28,555] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10000 type:create cxid:0x2 zxid:0xe7 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 08:02:28,555] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10000 type:create cxid:0x3 zxid:0xe8 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 08:02:28,560] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10000 type:create cxid:0x4 zxid:0xe9 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 08:02:28,565] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10000 type:create cxid:0x5 zxid:0xea txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 08:02:28,570] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10000 type:create cxid:0x6 zxid:0xeb txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 08:02:28,575] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10000 type:create cxid:0x7 zxid:0xec txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 08:02:28,580] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10000 type:create cxid:0x8 zxid:0xed txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 08:02:28,585] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10000 type:create cxid:0x9 zxid:0xee txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 08:02:28,590] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10000 type:create cxid:0xa zxid:0xef txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 08:02:28,595] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10000 type:create cxid:0xb zxid:0xf0 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 08:02:28,600] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10000 type:create cxid:0xc zxid:0xf1 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 08:02:28,605] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10000 type:create cxid:0xd zxid:0xf2 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 08:02:29,200] INFO Cluster ID = N2lSmjBdQoCizp4jp6C8fQ (kafka.server.KafkaServer)
[2020-02-27 08:02:29,432] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = c:\log
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-27 08:02:29,452] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = c:\log
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-27 08:02:29,560] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-27 08:02:29,560] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-27 08:02:29,560] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-27 08:02:29,652] INFO Loading logs. (kafka.log.LogManager)
[2020-02-27 08:02:29,868] INFO [Log partition=blog-approval-0, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:29,875] INFO [Log partition=blog-approval-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:30,088] INFO [ProducerStateManager partition=blog-approval-0] Writing producer snapshot at offset 35 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:30,178] INFO [Log partition=blog-approval-0, dir=c:\log] Loading producer state till offset 35 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:30,183] INFO [ProducerStateManager partition=blog-approval-0] Loading producer state from snapshot file 'c:\log\blog-approval-0\00000000000000000035.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:30,209] INFO [Log partition=blog-approval-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 35 in 421 ms (kafka.log.Log)
[2020-02-27 08:02:30,246] INFO [Log partition=blog-creation-0, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:30,247] INFO [Log partition=blog-creation-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:30,309] INFO [ProducerStateManager partition=blog-creation-0] Writing producer snapshot at offset 54 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:30,357] INFO [Log partition=blog-creation-0, dir=c:\log] Loading producer state till offset 54 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:30,367] INFO [ProducerStateManager partition=blog-creation-0] Loading producer state from snapshot file 'c:\log\blog-creation-0\00000000000000000054.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:30,369] INFO [Log partition=blog-creation-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 54 in 131 ms (kafka.log.Log)
[2020-02-27 08:02:30,384] INFO [Log partition=blog-key-0, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:30,385] INFO [Log partition=blog-key-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:30,421] INFO [ProducerStateManager partition=blog-key-0] Writing producer snapshot at offset 17 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:30,468] INFO [Log partition=blog-key-0, dir=c:\log] Loading producer state till offset 17 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:30,473] INFO [ProducerStateManager partition=blog-key-0] Loading producer state from snapshot file 'c:\log\blog-key-0\00000000000000000017.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:30,478] INFO [Log partition=blog-key-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 17 in 101 ms (kafka.log.Log)
[2020-02-27 08:02:30,526] INFO [Log partition=blog-notification-0, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:30,527] INFO [Log partition=blog-notification-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:30,558] INFO [ProducerStateManager partition=blog-notification-0] Writing producer snapshot at offset 22 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:30,591] INFO [Log partition=blog-notification-0, dir=c:\log] Loading producer state till offset 22 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:30,595] INFO [ProducerStateManager partition=blog-notification-0] Loading producer state from snapshot file 'c:\log\blog-notification-0\00000000000000000022.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:30,597] INFO [Log partition=blog-notification-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 22 in 82 ms (kafka.log.Log)
[2020-02-27 08:02:30,613] INFO [Log partition=__consumer_offsets-0, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:30,613] INFO [Log partition=__consumer_offsets-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:30,642] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:30,660] INFO [Log partition=__consumer_offsets-0, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:30,667] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'c:\log\__consumer_offsets-0\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:30,669] INFO [Log partition=__consumer_offsets-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 67 ms (kafka.log.Log)
[2020-02-27 08:02:30,682] INFO [Log partition=__consumer_offsets-1, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:30,685] INFO [Log partition=__consumer_offsets-1, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:30,736] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:30,776] INFO [Log partition=__consumer_offsets-1, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:30,824] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'c:\log\__consumer_offsets-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:30,875] INFO [Log partition=__consumer_offsets-1, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 199 ms (kafka.log.Log)
[2020-02-27 08:02:30,896] INFO [Log partition=__consumer_offsets-10, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:30,897] INFO [Log partition=__consumer_offsets-10, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:30,936] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:30,981] INFO [Log partition=__consumer_offsets-10, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:30,987] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'c:\log\__consumer_offsets-10\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:30,989] INFO [Log partition=__consumer_offsets-10, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 102 ms (kafka.log.Log)
[2020-02-27 08:02:31,003] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:31,005] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,043] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 14 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,077] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Loading producer state till offset 14 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,082] INFO [ProducerStateManager partition=__consumer_offsets-11] Loading producer state from snapshot file 'c:\log\__consumer_offsets-11\00000000000000000014.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,086] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 14 in 92 ms (kafka.log.Log)
[2020-02-27 08:02:31,103] INFO [Log partition=__consumer_offsets-12, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:31,104] INFO [Log partition=__consumer_offsets-12, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,138] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,162] INFO [Log partition=__consumer_offsets-12, dir=c:\log] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,165] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'c:\log\__consumer_offsets-12\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,167] INFO [Log partition=__consumer_offsets-12, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 73 ms (kafka.log.Log)
[2020-02-27 08:02:31,179] INFO [Log partition=__consumer_offsets-13, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:31,179] INFO [Log partition=__consumer_offsets-13, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,206] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,224] INFO [Log partition=__consumer_offsets-13, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,231] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'c:\log\__consumer_offsets-13\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,235] INFO [Log partition=__consumer_offsets-13, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 62 ms (kafka.log.Log)
[2020-02-27 08:02:31,247] INFO [Log partition=__consumer_offsets-14, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:31,248] INFO [Log partition=__consumer_offsets-14, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,274] INFO [ProducerStateManager partition=__consumer_offsets-14] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,295] INFO [Log partition=__consumer_offsets-14, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,299] INFO [ProducerStateManager partition=__consumer_offsets-14] Loading producer state from snapshot file 'c:\log\__consumer_offsets-14\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,300] INFO [Log partition=__consumer_offsets-14, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 60 ms (kafka.log.Log)
[2020-02-27 08:02:31,313] INFO [Log partition=__consumer_offsets-15, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:31,314] INFO [Log partition=__consumer_offsets-15, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,343] INFO [ProducerStateManager partition=__consumer_offsets-15] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,446] INFO [Log partition=__consumer_offsets-15, dir=c:\log] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,458] INFO [ProducerStateManager partition=__consumer_offsets-15] Loading producer state from snapshot file 'c:\log\__consumer_offsets-15\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,471] INFO [Log partition=__consumer_offsets-15, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 12 in 166 ms (kafka.log.Log)
[2020-02-27 08:02:31,504] INFO [Log partition=__consumer_offsets-16, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:31,515] INFO [Log partition=__consumer_offsets-16, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,557] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,594] INFO [Log partition=__consumer_offsets-16, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,598] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'c:\log\__consumer_offsets-16\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,601] INFO [Log partition=__consumer_offsets-16, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 107 ms (kafka.log.Log)
[2020-02-27 08:02:31,617] INFO [Log partition=__consumer_offsets-17, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:31,618] INFO [Log partition=__consumer_offsets-17, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,666] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,708] INFO [Log partition=__consumer_offsets-17, dir=c:\log] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,717] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'c:\log\__consumer_offsets-17\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,743] INFO [Log partition=__consumer_offsets-17, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 135 ms (kafka.log.Log)
[2020-02-27 08:02:31,763] INFO [Log partition=__consumer_offsets-18, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:31,763] INFO [Log partition=__consumer_offsets-18, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,817] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 13 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,859] INFO [Log partition=__consumer_offsets-18, dir=c:\log] Loading producer state till offset 13 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,886] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'c:\log\__consumer_offsets-18\00000000000000000013.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,893] INFO [Log partition=__consumer_offsets-18, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 13 in 139 ms (kafka.log.Log)
[2020-02-27 08:02:31,921] INFO [Log partition=__consumer_offsets-19, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:31,932] INFO [Log partition=__consumer_offsets-19, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,959] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,985] INFO [Log partition=__consumer_offsets-19, dir=c:\log] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:31,988] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file 'c:\log\__consumer_offsets-19\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:31,991] INFO [Log partition=__consumer_offsets-19, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 12 in 86 ms (kafka.log.Log)
[2020-02-27 08:02:32,005] INFO [Log partition=__consumer_offsets-2, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:32,006] INFO [Log partition=__consumer_offsets-2, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:32,053] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:32,081] INFO [Log partition=__consumer_offsets-2, dir=c:\log] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:32,087] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'c:\log\__consumer_offsets-2\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:32,091] INFO [Log partition=__consumer_offsets-2, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 94 ms (kafka.log.Log)
[2020-02-27 08:02:32,108] INFO [Log partition=__consumer_offsets-20, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:32,111] INFO [Log partition=__consumer_offsets-20, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:32,151] INFO [ProducerStateManager partition=__consumer_offsets-20] Writing producer snapshot at offset 32 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:32,184] INFO [Log partition=__consumer_offsets-20, dir=c:\log] Loading producer state till offset 32 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:32,192] INFO [ProducerStateManager partition=__consumer_offsets-20] Loading producer state from snapshot file 'c:\log\__consumer_offsets-20\00000000000000000032.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:32,194] INFO [Log partition=__consumer_offsets-20, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 32 in 97 ms (kafka.log.Log)
[2020-02-27 08:02:32,212] INFO [Log partition=__consumer_offsets-21, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:32,214] INFO [Log partition=__consumer_offsets-21, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:32,262] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 47 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:32,312] INFO [Log partition=__consumer_offsets-21, dir=c:\log] Loading producer state till offset 47 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:32,317] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'c:\log\__consumer_offsets-21\00000000000000000047.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:32,319] INFO [Log partition=__consumer_offsets-21, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 47 in 115 ms (kafka.log.Log)
[2020-02-27 08:02:32,332] INFO [Log partition=__consumer_offsets-22, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:32,335] INFO [Log partition=__consumer_offsets-22, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:32,378] INFO [ProducerStateManager partition=__consumer_offsets-22] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:32,411] INFO [Log partition=__consumer_offsets-22, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:32,415] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'c:\log\__consumer_offsets-22\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:32,417] INFO [Log partition=__consumer_offsets-22, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 92 ms (kafka.log.Log)
[2020-02-27 08:02:32,428] INFO [Log partition=__consumer_offsets-23, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:32,431] INFO [Log partition=__consumer_offsets-23, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:32,493] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:32,551] INFO [Log partition=__consumer_offsets-23, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:32,561] INFO [ProducerStateManager partition=__consumer_offsets-23] Loading producer state from snapshot file 'c:\log\__consumer_offsets-23\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:32,565] INFO [Log partition=__consumer_offsets-23, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 144 ms (kafka.log.Log)
[2020-02-27 08:02:32,581] INFO [Log partition=__consumer_offsets-24, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:32,583] INFO [Log partition=__consumer_offsets-24, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:32,662] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:32,769] INFO [Log partition=__consumer_offsets-24, dir=c:\log] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:32,775] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'c:\log\__consumer_offsets-24\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:32,777] INFO [Log partition=__consumer_offsets-24, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 206 ms (kafka.log.Log)
[2020-02-27 08:02:32,812] INFO [Log partition=__consumer_offsets-25, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:32,815] INFO [Log partition=__consumer_offsets-25, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:32,851] INFO [ProducerStateManager partition=__consumer_offsets-25] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:32,884] INFO [Log partition=__consumer_offsets-25, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:32,888] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file 'c:\log\__consumer_offsets-25\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:32,890] INFO [Log partition=__consumer_offsets-25, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 105 ms (kafka.log.Log)
[2020-02-27 08:02:32,928] INFO [Log partition=__consumer_offsets-26, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:32,930] INFO [Log partition=__consumer_offsets-26, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:32,974] INFO [ProducerStateManager partition=__consumer_offsets-26] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,018] INFO [Log partition=__consumer_offsets-26, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,040] INFO [ProducerStateManager partition=__consumer_offsets-26] Loading producer state from snapshot file 'c:\log\__consumer_offsets-26\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,042] INFO [Log partition=__consumer_offsets-26, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 146 ms (kafka.log.Log)
[2020-02-27 08:02:33,059] INFO [Log partition=__consumer_offsets-27, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:33,061] INFO [Log partition=__consumer_offsets-27, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,118] INFO [ProducerStateManager partition=__consumer_offsets-27] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,218] INFO [Log partition=__consumer_offsets-27, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,225] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'c:\log\__consumer_offsets-27\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,229] INFO [Log partition=__consumer_offsets-27, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 178 ms (kafka.log.Log)
[2020-02-27 08:02:33,241] INFO [Log partition=__consumer_offsets-28, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:33,242] INFO [Log partition=__consumer_offsets-28, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,269] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 36 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,306] INFO [Log partition=__consumer_offsets-28, dir=c:\log] Loading producer state till offset 36 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,310] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'c:\log\__consumer_offsets-28\00000000000000000036.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,312] INFO [Log partition=__consumer_offsets-28, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 36 in 77 ms (kafka.log.Log)
[2020-02-27 08:02:33,340] INFO [Log partition=__consumer_offsets-29, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:33,348] INFO [Log partition=__consumer_offsets-29, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,398] INFO [ProducerStateManager partition=__consumer_offsets-29] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,423] INFO [Log partition=__consumer_offsets-29, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,426] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file 'c:\log\__consumer_offsets-29\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,428] INFO [Log partition=__consumer_offsets-29, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 97 ms (kafka.log.Log)
[2020-02-27 08:02:33,438] INFO [Log partition=__consumer_offsets-3, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:33,439] INFO [Log partition=__consumer_offsets-3, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,475] INFO [Log partition=__consumer_offsets-3, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,484] INFO [Log partition=__consumer_offsets-3, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 53 ms (kafka.log.Log)
[2020-02-27 08:02:33,521] INFO [Log partition=__consumer_offsets-30, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:33,523] INFO [Log partition=__consumer_offsets-30, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,565] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,600] INFO [Log partition=__consumer_offsets-30, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,606] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file 'c:\log\__consumer_offsets-30\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,609] INFO [Log partition=__consumer_offsets-30, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 99 ms (kafka.log.Log)
[2020-02-27 08:02:33,625] INFO [Log partition=__consumer_offsets-31, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:33,626] INFO [Log partition=__consumer_offsets-31, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,658] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,719] INFO [Log partition=__consumer_offsets-31, dir=c:\log] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,724] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'c:\log\__consumer_offsets-31\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,725] INFO [Log partition=__consumer_offsets-31, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 108 ms (kafka.log.Log)
[2020-02-27 08:02:33,735] INFO [Log partition=__consumer_offsets-32, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:33,737] INFO [Log partition=__consumer_offsets-32, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,761] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,785] INFO [Log partition=__consumer_offsets-32, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,790] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'c:\log\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,793] INFO [Log partition=__consumer_offsets-32, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 66 ms (kafka.log.Log)
[2020-02-27 08:02:33,805] INFO [Log partition=__consumer_offsets-33, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:33,807] INFO [Log partition=__consumer_offsets-33, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,832] INFO [ProducerStateManager partition=__consumer_offsets-33] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,863] INFO [Log partition=__consumer_offsets-33, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,874] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file 'c:\log\__consumer_offsets-33\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:33,888] INFO [Log partition=__consumer_offsets-33, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 90 ms (kafka.log.Log)
[2020-02-27 08:02:33,897] INFO [Log partition=__consumer_offsets-34, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:33,897] INFO [Log partition=__consumer_offsets-34, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,930] INFO [Log partition=__consumer_offsets-34, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,938] INFO [Log partition=__consumer_offsets-34, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2020-02-27 08:02:33,951] INFO [Log partition=__consumer_offsets-35, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:33,953] INFO [Log partition=__consumer_offsets-35, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:33,996] INFO [Log partition=__consumer_offsets-35, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,001] INFO [Log partition=__consumer_offsets-35, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2020-02-27 08:02:34,045] INFO [Log partition=__consumer_offsets-36, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:34,075] INFO [Log partition=__consumer_offsets-36, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,125] INFO [Log partition=__consumer_offsets-36, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,131] INFO [Log partition=__consumer_offsets-36, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 127 ms (kafka.log.Log)
[2020-02-27 08:02:34,144] INFO [Log partition=__consumer_offsets-37, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:34,158] INFO [Log partition=__consumer_offsets-37, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,243] INFO [ProducerStateManager partition=__consumer_offsets-37] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,291] INFO [Log partition=__consumer_offsets-37, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,295] INFO [ProducerStateManager partition=__consumer_offsets-37] Loading producer state from snapshot file 'c:\log\__consumer_offsets-37\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,299] INFO [Log partition=__consumer_offsets-37, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 162 ms (kafka.log.Log)
[2020-02-27 08:02:34,321] INFO [Log partition=__consumer_offsets-38, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:34,323] INFO [Log partition=__consumer_offsets-38, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,349] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,375] INFO [Log partition=__consumer_offsets-38, dir=c:\log] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,379] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'c:\log\__consumer_offsets-38\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,380] INFO [Log partition=__consumer_offsets-38, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 73 ms (kafka.log.Log)
[2020-02-27 08:02:34,391] INFO [Log partition=__consumer_offsets-39, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:34,393] INFO [Log partition=__consumer_offsets-39, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,416] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,436] INFO [Log partition=__consumer_offsets-39, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,440] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'c:\log\__consumer_offsets-39\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,442] INFO [Log partition=__consumer_offsets-39, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 58 ms (kafka.log.Log)
[2020-02-27 08:02:34,453] INFO [Log partition=__consumer_offsets-4, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:34,454] INFO [Log partition=__consumer_offsets-4, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,486] INFO [Log partition=__consumer_offsets-4, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,492] INFO [Log partition=__consumer_offsets-4, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2020-02-27 08:02:34,506] INFO [Log partition=__consumer_offsets-40, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:34,507] INFO [Log partition=__consumer_offsets-40, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,539] INFO [ProducerStateManager partition=__consumer_offsets-40] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,559] INFO [Log partition=__consumer_offsets-40, dir=c:\log] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,562] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'c:\log\__consumer_offsets-40\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,563] INFO [Log partition=__consumer_offsets-40, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 64 ms (kafka.log.Log)
[2020-02-27 08:02:34,572] INFO [Log partition=__consumer_offsets-41, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:34,573] INFO [Log partition=__consumer_offsets-41, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,596] INFO [ProducerStateManager partition=__consumer_offsets-41] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,668] INFO [Log partition=__consumer_offsets-41, dir=c:\log] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,676] INFO [ProducerStateManager partition=__consumer_offsets-41] Loading producer state from snapshot file 'c:\log\__consumer_offsets-41\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,681] INFO [Log partition=__consumer_offsets-41, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 116 ms (kafka.log.Log)
[2020-02-27 08:02:34,692] INFO [Log partition=__consumer_offsets-42, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:34,694] INFO [Log partition=__consumer_offsets-42, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,724] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,760] INFO [Log partition=__consumer_offsets-42, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,762] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file 'c:\log\__consumer_offsets-42\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,763] INFO [Log partition=__consumer_offsets-42, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 78 ms (kafka.log.Log)
[2020-02-27 08:02:34,772] INFO [Log partition=__consumer_offsets-43, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:34,773] INFO [Log partition=__consumer_offsets-43, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,801] INFO [ProducerStateManager partition=__consumer_offsets-43] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,821] INFO [Log partition=__consumer_offsets-43, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,824] INFO [ProducerStateManager partition=__consumer_offsets-43] Loading producer state from snapshot file 'c:\log\__consumer_offsets-43\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,825] INFO [Log partition=__consumer_offsets-43, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 60 ms (kafka.log.Log)
[2020-02-27 08:02:34,833] INFO [Log partition=__consumer_offsets-44, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:34,834] INFO [Log partition=__consumer_offsets-44, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,875] INFO [ProducerStateManager partition=__consumer_offsets-44] Writing producer snapshot at offset 23 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,895] INFO [Log partition=__consumer_offsets-44, dir=c:\log] Loading producer state till offset 23 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,898] INFO [ProducerStateManager partition=__consumer_offsets-44] Loading producer state from snapshot file 'c:\log\__consumer_offsets-44\00000000000000000023.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:34,899] INFO [Log partition=__consumer_offsets-44, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 23 in 72 ms (kafka.log.Log)
[2020-02-27 08:02:34,913] INFO [Log partition=__consumer_offsets-45, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:34,918] INFO [Log partition=__consumer_offsets-45, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:34,977] INFO [ProducerStateManager partition=__consumer_offsets-45] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,005] INFO [Log partition=__consumer_offsets-45, dir=c:\log] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,008] INFO [ProducerStateManager partition=__consumer_offsets-45] Loading producer state from snapshot file 'c:\log\__consumer_offsets-45\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,011] INFO [Log partition=__consumer_offsets-45, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 12 in 109 ms (kafka.log.Log)
[2020-02-27 08:02:35,020] INFO [Log partition=__consumer_offsets-46, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:35,021] INFO [Log partition=__consumer_offsets-46, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,052] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,084] INFO [Log partition=__consumer_offsets-46, dir=c:\log] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,088] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'c:\log\__consumer_offsets-46\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,091] INFO [Log partition=__consumer_offsets-46, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 78 ms (kafka.log.Log)
[2020-02-27 08:02:35,103] INFO [Log partition=__consumer_offsets-47, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:35,105] INFO [Log partition=__consumer_offsets-47, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,135] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,154] INFO [Log partition=__consumer_offsets-47, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,157] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'c:\log\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,158] INFO [Log partition=__consumer_offsets-47, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 64 ms (kafka.log.Log)
[2020-02-27 08:02:35,168] INFO [Log partition=__consumer_offsets-48, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:35,169] INFO [Log partition=__consumer_offsets-48, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,194] INFO [ProducerStateManager partition=__consumer_offsets-48] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,213] INFO [Log partition=__consumer_offsets-48, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,216] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file 'c:\log\__consumer_offsets-48\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,218] INFO [Log partition=__consumer_offsets-48, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 57 ms (kafka.log.Log)
[2020-02-27 08:02:35,228] INFO [Log partition=__consumer_offsets-49, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:35,240] INFO [Log partition=__consumer_offsets-49, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,278] INFO [ProducerStateManager partition=__consumer_offsets-49] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,297] INFO [Log partition=__consumer_offsets-49, dir=c:\log] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,300] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file 'c:\log\__consumer_offsets-49\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,301] INFO [Log partition=__consumer_offsets-49, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 80 ms (kafka.log.Log)
[2020-02-27 08:02:35,310] INFO [Log partition=__consumer_offsets-5, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:35,311] INFO [Log partition=__consumer_offsets-5, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,353] INFO [ProducerStateManager partition=__consumer_offsets-5] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,368] INFO [Log partition=__consumer_offsets-5, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,373] INFO [ProducerStateManager partition=__consumer_offsets-5] Loading producer state from snapshot file 'c:\log\__consumer_offsets-5\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,376] INFO [Log partition=__consumer_offsets-5, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 72 ms (kafka.log.Log)
[2020-02-27 08:02:35,383] INFO [Log partition=__consumer_offsets-6, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:35,383] INFO [Log partition=__consumer_offsets-6, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,415] INFO [Log partition=__consumer_offsets-6, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,415] INFO [Log partition=__consumer_offsets-6, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2020-02-27 08:02:35,425] INFO [Log partition=__consumer_offsets-7, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:35,430] INFO [Log partition=__consumer_offsets-7, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,475] INFO [ProducerStateManager partition=__consumer_offsets-7] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,525] INFO [Log partition=__consumer_offsets-7, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,535] INFO [ProducerStateManager partition=__consumer_offsets-7] Loading producer state from snapshot file 'c:\log\__consumer_offsets-7\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,541] INFO [Log partition=__consumer_offsets-7, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 121 ms (kafka.log.Log)
[2020-02-27 08:02:35,596] INFO [Log partition=__consumer_offsets-8, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:35,626] INFO [Log partition=__consumer_offsets-8, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,661] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,691] INFO [Log partition=__consumer_offsets-8, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,696] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'c:\log\__consumer_offsets-8\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 08:02:35,701] INFO [Log partition=__consumer_offsets-8, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 145 ms (kafka.log.Log)
[2020-02-27 08:02:35,714] INFO [Log partition=__consumer_offsets-9, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 08:02:35,714] INFO [Log partition=__consumer_offsets-9, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,796] INFO [Log partition=__consumer_offsets-9, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 08:02:35,801] INFO [Log partition=__consumer_offsets-9, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 95 ms (kafka.log.Log)
[2020-02-27 08:02:35,806] INFO Logs loading complete in 6152 ms. (kafka.log.LogManager)
[2020-02-27 08:02:35,838] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-02-27 08:02:35,838] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-02-27 08:02:36,689] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2020-02-27 08:02:36,791] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-02-27 08:02:36,796] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-02-27 08:02:36,994] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 08:02:37,010] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 08:02:37,010] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 08:02:37,010] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 08:02:37,010] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-02-27 08:02:37,175] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-02-27 08:02:37,229] INFO Stat of the created znode at /brokers/ids/0 is: 243,243,1582765357213,1582765357213,1,0,0,72135757456801792,188,0,243
 (kafka.zk.KafkaZkClient)
[2020-02-27 08:02:37,234] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 243 (kafka.zk.KafkaZkClient)
[2020-02-27 08:02:37,364] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 08:02:37,369] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 08:02:37,369] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 08:02:37,532] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:37,595] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:37,636] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:37,667] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:4000,blockEndProducerId:4999) by writing to Zk with path version 5 (kafka.coordinator.transaction.ProducerIdManager)
[2020-02-27 08:02:37,755] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-02-27 08:02:37,792] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-02-27 08:02:37,834] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-02-27 08:02:38,048] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10000 type:multi cxid:0x69 zxid:0xf6 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 08:02:38,091] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-02-27 08:02:38,158] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-02-27 08:02:38,203] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-02-27 08:02:38,208] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2020-02-27 08:02:38,208] INFO Kafka startTimeMs: 1582765358168 (org.apache.kafka.common.utils.AppInfoParser)
[2020-02-27 08:02:38,218] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-02-27 08:02:38,605] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, blog-creation-0, blog-approval-0, blog-notification-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, blog-key-0, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-02-27 08:02:38,660] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 6 (kafka.cluster.Replica)
[2020-02-27 08:02:38,675] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,730] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 6 (kafka.cluster.Replica)
[2020-02-27 08:02:38,745] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,760] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 6 (kafka.cluster.Replica)
[2020-02-27 08:02:38,765] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,781] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 3 (kafka.cluster.Replica)
[2020-02-27 08:02:38,781] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,791] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 12 (kafka.cluster.Replica)
[2020-02-27 08:02:38,794] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 12. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,801] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 6 (kafka.cluster.Replica)
[2020-02-27 08:02:38,806] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,811] INFO Replica loaded for partition blog-approval-0 with initial high watermark 35 (kafka.cluster.Replica)
[2020-02-27 08:02:38,811] INFO [Partition blog-approval-0 broker=0] blog-approval-0 starts at Leader Epoch 0 from offset 35. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,819] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 6 (kafka.cluster.Replica)
[2020-02-27 08:02:38,819] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,821] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 3 (kafka.cluster.Replica)
[2020-02-27 08:02:38,826] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,826] INFO Replica loaded for partition blog-key-0 with initial high watermark 17 (kafka.cluster.Replica)
[2020-02-27 08:02:38,831] INFO [Partition blog-key-0 broker=0] blog-key-0 starts at Leader Epoch 0 from offset 17. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,836] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 08:02:38,841] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,886] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 6 (kafka.cluster.Replica)
[2020-02-27 08:02:38,901] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,906] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 6 (kafka.cluster.Replica)
[2020-02-27 08:02:38,906] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,911] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 32 (kafka.cluster.Replica)
[2020-02-27 08:02:38,911] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 32. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,919] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 6 (kafka.cluster.Replica)
[2020-02-27 08:02:38,921] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,926] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 9 (kafka.cluster.Replica)
[2020-02-27 08:02:38,931] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 9. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,936] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 08:02:38,936] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,991] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 6 (kafka.cluster.Replica)
[2020-02-27 08:02:38,991] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:38,996] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 3 (kafka.cluster.Replica)
[2020-02-27 08:02:38,996] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,001] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 4 (kafka.cluster.Replica)
[2020-02-27 08:02:39,006] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,011] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 14 (kafka.cluster.Replica)
[2020-02-27 08:02:39,011] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 14. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,016] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 3 (kafka.cluster.Replica)
[2020-02-27 08:02:39,016] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,022] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 9 (kafka.cluster.Replica)
[2020-02-27 08:02:39,023] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 9. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,030] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 3 (kafka.cluster.Replica)
[2020-02-27 08:02:39,032] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,036] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 3 (kafka.cluster.Replica)
[2020-02-27 08:02:39,037] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,041] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 11 (kafka.cluster.Replica)
[2020-02-27 08:02:39,042] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 11. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,043] INFO Replica loaded for partition blog-notification-0 with initial high watermark 22 (kafka.cluster.Replica)
[2020-02-27 08:02:39,048] INFO [Partition blog-notification-0 broker=0] blog-notification-0 starts at Leader Epoch 0 from offset 22. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,053] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 6 (kafka.cluster.Replica)
[2020-02-27 08:02:39,058] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,058] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 3 (kafka.cluster.Replica)
[2020-02-27 08:02:39,066] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,068] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 47 (kafka.cluster.Replica)
[2020-02-27 08:02:39,073] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 47. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,073] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 7 (kafka.cluster.Replica)
[2020-02-27 08:02:39,078] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,083] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 5 (kafka.cluster.Replica)
[2020-02-27 08:02:39,088] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,091] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 3 (kafka.cluster.Replica)
[2020-02-27 08:02:39,091] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,093] INFO Replica loaded for partition blog-creation-0 with initial high watermark 54 (kafka.cluster.Replica)
[2020-02-27 08:02:39,093] INFO [Partition blog-creation-0 broker=0] blog-creation-0 starts at Leader Epoch 0 from offset 54. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,103] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 13 (kafka.cluster.Replica)
[2020-02-27 08:02:39,103] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 13. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,108] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 08:02:39,108] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,158] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 12 (kafka.cluster.Replica)
[2020-02-27 08:02:39,158] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 12. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,163] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 10 (kafka.cluster.Replica)
[2020-02-27 08:02:39,167] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 10. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,174] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 5 (kafka.cluster.Replica)
[2020-02-27 08:02:39,174] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,179] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 08:02:39,179] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,199] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 3 (kafka.cluster.Replica)
[2020-02-27 08:02:39,204] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,209] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 12 (kafka.cluster.Replica)
[2020-02-27 08:02:39,209] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 12. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,214] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 36 (kafka.cluster.Replica)
[2020-02-27 08:02:39,217] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 36. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,219] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 4 (kafka.cluster.Replica)
[2020-02-27 08:02:39,219] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,224] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 08:02:39,224] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,244] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 08:02:39,244] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,259] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 23 (kafka.cluster.Replica)
[2020-02-27 08:02:39,259] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 23. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,289] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 6 (kafka.cluster.Replica)
[2020-02-27 08:02:39,289] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,294] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 3 (kafka.cluster.Replica)
[2020-02-27 08:02:39,294] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,299] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 3 (kafka.cluster.Replica)
[2020-02-27 08:02:39,299] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,304] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 10 (kafka.cluster.Replica)
[2020-02-27 08:02:39,304] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 10. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,309] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2020-02-27 08:02:39,309] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,324] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 08:02:39,334] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,389] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 3 (kafka.cluster.Replica)
[2020-02-27 08:02:39,415] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 08:02:39,460] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,478] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,515] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,540] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,553] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,565] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,596] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,591] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.960c69f8-e5c1-4c7a-adc5-7e76c446eb9d with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,596] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,601] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,604] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 126 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,606] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,606] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,606] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,611] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,611] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,611] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,611] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,616] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.3c1d5e91-438d-40bd-8e28-1e1649daac57 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,616] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,616] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,616] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,616] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,621] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,626] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,626] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,626] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,629] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,629] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,631] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,631] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,631] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,631] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,631] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,636] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,636] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,636] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,641] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,641] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,641] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,641] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,641] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,646] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,646] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,646] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,646] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,651] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,654] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,654] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,656] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,656] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,656] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,661] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.cb9a2b36-287e-4063-be9f-492ee500adad with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,686] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.c3e26ba4-643d-4b4a-b93b-88816791da0d with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,726] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.3dc86edf-bf8a-4454-8377-d2311036a4b2 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,726] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.d7b5895e-ad49-4a93-8815-5ba14cba2cbe with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,726] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.ca7a5c6e-ff0d-4a00-b546-a0b4cced6fe7 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,731] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 115 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,736] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.54e34caa-7f56-47dc-9ae5-1c1963a7962f with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 30 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,779] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,786] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.9853adcd-c1fb-415a-a68f-c19ab30ec952 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,791] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,806] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.1614edd3-c525-4210-acfa-f3683cfecd0e with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,816] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 20 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,831] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.8d3460de-4f7b-4ffe-aadd-32d471597868 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,838] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.ab9f71fa-aec0-4e5f-9865-f9eada6df480 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,840] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 19 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,847] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.001e56e3-bc31-4b54-88ce-cd07a5530ad7 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,857] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.f69d29c2-d684-4f5a-acd6-6f286d2e77e0 with generation 4 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,862] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 21 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,870] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.f02047f9-bbe9-40f1-8794-89adfdd5b19d with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,872] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,877] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.97648cc2-1e55-4a1b-8d69-44446ce08a31 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,882] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.8aeb59d2-eeb1-41e9-9df7-0597e4626299 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,882] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.a2f2dc5d-c92a-41b4-a499-f90180bba5b6 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,887] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,907] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.5dc6f591-2535-4d62-b5aa-d0d2f5b73ad2 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,912] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.0e3e2178-2c6b-4d35-8725-8c8936e9d769 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,912] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.2fce36a0-7404-4009-ac41-40d1f55e294a with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,927] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.962ace4b-d60e-478d-8131-ce18f601d45c with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,927] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 30 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,937] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.d83a47d5-ce4e-4e84-9227-ebaa6624ed4b with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,947] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 20 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,962] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.647f7ec5-b771-4264-8374-48a9643b39a0 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,972] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.e48588ec-99d7-42d6-b0ac-a08d4ce9372a with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,972] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 20 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,977] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,987] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.ec0fa26f-4c70-419d-b256-f560df3e43df with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,987] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.cd332a50-4373-4fff-b7e8-9815da1cd69a with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,987] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:39,997] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.2fd2bdaf-21ed-4e34-926b-1362f4d96f24 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:39,997] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,007] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.2c97d420-6740-43c0-a521-70988cb53143 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,007] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,012] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.69d97b10-4cae-4b70-bde3-43fadcf400e9 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,020] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,032] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.c326ed6b-a9ea-4286-90a4-2a29bc6c5da1 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,037] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,052] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.5382aeeb-6cd6-4dd2-ba90-f284f585e004 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,057] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.89c0d58d-cabc-4af9-9996-7a6e4ba4f47a with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,057] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,067] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.ee37cdc4-dbca-4615-b971-4b52715e30cb with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,070] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,077] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.0842f664-87b3-4f0f-abae-19f78237e604 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,082] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,095] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.8909ce44-906d-4bf3-b746-44469459bc6a with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,095] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.57bf6ae7-809d-45ff-b440-b25ce1712173 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,097] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.305a5eb6-20a2-4caf-8200-ba6fbf5c9bae with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,102] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.45ac2162-17a4-4c7a-8d4d-3d3118b8471d with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,112] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 30 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,127] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.97234a28-300a-483f-8e13-5f603ece1c9e with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,137] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.edece584-2b31-4631-922d-627865248638 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 14 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,148] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.402feb3f-bf4c-4d9c-b438-a8c5d158dc4d with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,153] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.36495d28-fcf9-4e08-ae8d-a17277dff98d with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,158] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.ed71d606-6f23-42df-8346-b886b600047f with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,163] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 21 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,183] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.066f0e32-5a8d-4464-91c9-b89219a7e104 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,183] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.db49c5b0-dce2-4ce9-ac2e-47bf56aa87a8 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,188] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.ab8fe8a3-040d-42bb-a998-c07b39efc138 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,213] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.406b9d91-2bc4-4a83-aebb-fc122fffeacd with generation 3 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,243] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.859fe528-bf2e-4701-be78-64a812fe32d2 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,248] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.2e6946b2-fb68-4d12-9033-b40515bd0b11 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,253] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.20918862-adda-416e-8142-34123c804a3b with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,258] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 87 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,271] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.5c27e437-ebe0-48bb-97a2-fc73bf1f8418 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,273] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.a89fc8f3-4c74-4dda-914b-1bfd5c4f8921 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,273] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,283] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.0d7bd6ae-fc2d-48b8-a086-bf67c9166f8f with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,288] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.b188e417-8820-4559-956c-7287a091cb49 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,288] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,298] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.cf8ba417-cf37-4571-9702-6b933cbfd39d with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,298] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.38a2426c-e6a2-4d86-8e6d-e4d4b24d7c63 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,303] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,308] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.a7966f3c-76cf-4466-b9c8-aa31894e14a4 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,318] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,323] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,338] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.7bc0bae3-02a0-4a31-a1c8-6569a777e30a with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,346] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 23 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,363] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.3c33651a-d8dc-4d73-9265-77247f49046e with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,368] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.cbe55c3c-f5da-460a-b514-9dbaec742a67 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,368] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 20 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,378] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,393] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,403] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,408] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.6cd2a3f2-6cf9-4b29-a875-1ea91ef4df99 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,413] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.d38eb514-1b84-4e7d-9a3a-fa8d5f02273f with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,413] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.88325ae1-8828-4b7e-92a2-940189f32510 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,413] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,424] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.edc5b9f2-73bd-477d-9d91-791ea4223eb4 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,424] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.9fb8dc1d-9389-44eb-853a-66346253832f with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,424] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.555fd4ca-60c3-4bef-8485-8125d056ceee with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,424] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.aa3b92f5-4596-467a-bb01-8ffebffb7363 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,429] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,439] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.24c638ac-6161-4472-a0aa-f94ea9d0488c with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,449] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.c32aa2bf-518b-4c73-bf9e-d3c331107abb with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,454] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.857b1359-376d-41ab-8b38-fd1389402aae with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,459] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.c9318a4b-4dae-49bb-bfc0-bf931b517a9f with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,469] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 40 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,484] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.b8c4e6b7-29f4-4f70-921c-9b71369b129e with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,484] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.8c97d95c-55f4-4919-9958-5c8c28cb6396 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,484] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.d1790124-815e-4f08-85b8-b89be87a1e1e with generation 4 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,484] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.45560284-bc50-4f70-8434-61619fc1685f with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,489] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 17 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,518] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.b73f3ad1-769b-478e-8865-4b1a8bbf1174 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,546] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.39b5b46c-8fd8-449f-9237-08025455feab with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,550] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.5f17ba9e-0984-43d2-b2b6-8001f9a6b598 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,551] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 62 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,587] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.2c980865-6a52-485a-b37c-992750908e2d with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,592] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 39 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,601] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.fa9a52aa-4e8a-4495-afad-f575dc30efc6 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,603] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,610] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.8c72d00d-ca98-421f-b873-a2135ae8a34b with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,612] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,623] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,644] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.ad4a2e9f-aadf-4a67-8a90-8da60c98fb69 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,646] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.6875b20d-2e09-4591-a20b-d78ee5f28583 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,649] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,655] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.42550b37-fffc-44fe-8f8a-facab15d7644 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,657] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,666] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.e3e9e347-fd91-45c3-beb5-d73de1cc2b73 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,668] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:40,677] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.9f8f3f26-c903-4af2-9a42-f33151ccaad6 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,678] INFO [GroupCoordinator 0]: Loading group metadata for anonymous.7577fcdc-48af-4c9b-b8f4-90f56007635a with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:40,680] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:02:50,253] INFO [GroupCoordinator 0]: Member consumer-2-c21b37b4-1577-4edf-8ba5-8fe32aee64ac in group anonymous.406b9d91-2bc4-4a83-aebb-fc122fffeacd has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:50,269] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.406b9d91-2bc4-4a83-aebb-fc122fffeacd in state PreparingRebalance with old generation 3 (__consumer_offsets-20) (reason: removing member consumer-2-c21b37b4-1577-4edf-8ba5-8fe32aee64ac on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:02:50,319] INFO [GroupCoordinator 0]: Group anonymous.406b9d91-2bc4-4a83-aebb-fc122fffeacd with generation 4 is now empty (__consumer_offsets-20) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:05:39,164] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.03c6ca33-e520-4584-8385-3f7fac0bbcb3 in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-2-9828448b-ee56-4b0b-a6eb-3a2a67bcf958 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:05:39,300] INFO [GroupCoordinator 0]: Stabilized group anonymous.03c6ca33-e520-4584-8385-3f7fac0bbcb3 generation 1 (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:05:39,396] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.03c6ca33-e520-4584-8385-3f7fac0bbcb3 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:05:40,255] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.115d94cc-ea1a-445e-a554-952baa97e103 in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member consumer-4-9b653097-b620-4635-9988-4c5014ac2742 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:05:40,290] INFO [GroupCoordinator 0]: Stabilized group anonymous.115d94cc-ea1a-445e-a554-952baa97e103 generation 1 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:05:40,301] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.115d94cc-ea1a-445e-a554-952baa97e103 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:05:40,640] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.95db0f38-f46c-4582-81bc-02ccfbd38f58 in state PreparingRebalance with old generation 0 (__consumer_offsets-14) (reason: Adding new member consumer-6-b1e0c269-691a-41be-89c2-3ef7a89180d0 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:05:40,662] INFO [GroupCoordinator 0]: Stabilized group anonymous.95db0f38-f46c-4582-81bc-02ccfbd38f58 generation 1 (__consumer_offsets-14) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:05:40,677] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.95db0f38-f46c-4582-81bc-02ccfbd38f58 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:06:37,861] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.e79a2ad1-f9c4-41f1-b3e1-f752192a7777 in state PreparingRebalance with old generation 0 (__consumer_offsets-25) (reason: Adding new member consumer-2-46bc971e-b6f8-4979-8532-5764f5d2ce7d with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:06:37,886] INFO [GroupCoordinator 0]: Stabilized group anonymous.e79a2ad1-f9c4-41f1-b3e1-f752192a7777 generation 1 (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:06:37,898] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.e79a2ad1-f9c4-41f1-b3e1-f752192a7777 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:12:38,878] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:22:38,893] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:28:46,046] INFO [GroupCoordinator 0]: Member consumer-2-9828448b-ee56-4b0b-a6eb-3a2a67bcf958 in group anonymous.03c6ca33-e520-4584-8385-3f7fac0bbcb3 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:28:46,049] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.03c6ca33-e520-4584-8385-3f7fac0bbcb3 in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: removing member consumer-2-9828448b-ee56-4b0b-a6eb-3a2a67bcf958 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:28:46,052] INFO [GroupCoordinator 0]: Group anonymous.03c6ca33-e520-4584-8385-3f7fac0bbcb3 with generation 2 is now empty (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:28:46,100] INFO [GroupCoordinator 0]: Member consumer-4-9b653097-b620-4635-9988-4c5014ac2742 in group anonymous.115d94cc-ea1a-445e-a554-952baa97e103 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:28:46,100] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.115d94cc-ea1a-445e-a554-952baa97e103 in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: removing member consumer-4-9b653097-b620-4635-9988-4c5014ac2742 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:28:46,103] INFO [GroupCoordinator 0]: Group anonymous.115d94cc-ea1a-445e-a554-952baa97e103 with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:28:46,139] INFO [GroupCoordinator 0]: Member consumer-6-b1e0c269-691a-41be-89c2-3ef7a89180d0 in group anonymous.95db0f38-f46c-4582-81bc-02ccfbd38f58 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:28:46,140] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.95db0f38-f46c-4582-81bc-02ccfbd38f58 in state PreparingRebalance with old generation 1 (__consumer_offsets-14) (reason: removing member consumer-6-b1e0c269-691a-41be-89c2-3ef7a89180d0 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:28:46,145] INFO [GroupCoordinator 0]: Group anonymous.95db0f38-f46c-4582-81bc-02ccfbd38f58 with generation 2 is now empty (__consumer_offsets-14) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:32:38,897] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:42:38,928] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:49:42,646] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.841dcaf6-6cda-4618-8b64-051f9644ca99 in state PreparingRebalance with old generation 0 (__consumer_offsets-34) (reason: Adding new member consumer-2-bf9cd35a-e67d-42dc-b865-fa6bf20860c7 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:49:42,659] INFO [GroupCoordinator 0]: Stabilized group anonymous.841dcaf6-6cda-4618-8b64-051f9644ca99 generation 1 (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:49:42,679] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.841dcaf6-6cda-4618-8b64-051f9644ca99 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:49:42,892] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.31bc5bc8-0f0a-4dae-ab54-0ce9ac2a454c in state PreparingRebalance with old generation 0 (__consumer_offsets-49) (reason: Adding new member consumer-4-9fbac484-1caf-4b73-846b-11d2d23b7304 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:49:42,899] INFO [GroupCoordinator 0]: Stabilized group anonymous.31bc5bc8-0f0a-4dae-ab54-0ce9ac2a454c generation 1 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:49:42,908] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.31bc5bc8-0f0a-4dae-ab54-0ce9ac2a454c for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:49:43,184] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.7764c53f-b221-40a7-86c9-a1341c63a489 in state PreparingRebalance with old generation 0 (__consumer_offsets-11) (reason: Adding new member consumer-6-9f33a827-9a94-462b-b1e6-123adc1076ec with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:49:43,192] INFO [GroupCoordinator 0]: Stabilized group anonymous.7764c53f-b221-40a7-86c9-a1341c63a489 generation 1 (__consumer_offsets-11) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:49:43,196] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.7764c53f-b221-40a7-86c9-a1341c63a489 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 08:52:38,952] INFO [GroupMetadataManager brokerId=0] Group anonymous.45ac2162-17a4-4c7a-8d4d-3d3118b8471d transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:52:39,004] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 16 (kafka.log.ProducerStateManager)
[2020-02-27 08:52:39,021] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Rolled new log segment at offset 16 in 50 ms. (kafka.log.Log)
[2020-02-27 08:52:39,084] INFO [GroupMetadataManager brokerId=0] Group anonymous.45560284-bc50-4f70-8434-61619fc1685f transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:52:39,263] INFO [Log partition=__consumer_offsets-21, dir=c:\log] Rolled new log segment at offset 47 in 150 ms. (kafka.log.Log)
[2020-02-27 08:52:39,283] INFO [GroupMetadataManager brokerId=0] Removed 2 expired offsets in 343 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 08:52:39,578] ERROR Failed to clean up log for __consumer_offsets-11 in dir c:\log due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: c:\log\__consumer_offsets-11\00000000000000000000.timeindex.cleaned -> c:\log\__consumer_offsets-11\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2016)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2016)
	at kafka.log.Log$$Lambda$1223/1773822487.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2016)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at kafka.log.Cleaner$$Lambda$1214/1922687433.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: c:\log\__consumer_offsets-11\00000000000000000000.timeindex.cleaned -> c:\log\__consumer_offsets-11\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 18 more
[2020-02-27 08:52:39,584] INFO [ReplicaManager broker=0] Stopping serving replicas in dir c:\log (kafka.server.ReplicaManager)
[2020-02-27 08:52:39,591] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, blog-creation-0, blog-approval-0, blog-notification-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, blog-key-0, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-02-27 08:52:39,595] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, blog-creation-0, blog-approval-0, blog-notification-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, blog-key-0, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaAlterLogDirsManager)
[2020-02-27 08:52:39,668] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,blog-creation-0,blog-approval-0,blog-notification-0,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,blog-key-0,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 and stopped moving logs for partitions  because they are in the failed log directory c:\log. (kafka.server.ReplicaManager)
[2020-02-27 08:52:39,674] INFO Stopping serving logs in dir c:\log (kafka.log.LogManager)
[2020-02-27 08:52:39,690] ERROR Shutdown broker because all log dirs in c:\log have failed (kafka.log.LogManager)
[2020-02-27 08:52:40,044] WARN Exception causing close of session 0x1004716d6d10000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-27 08:52:40,079] INFO Closed socket connection for client /127.0.0.1:62337 which had sessionid 0x1004716d6d10000 (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-27 08:52:48,641] INFO Expiring session 0x1004716d6d10000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 08:52:48,643] INFO Processed session termination for sessionid: 0x1004716d6d10000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:21:36,801] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-02-27 09:21:37,980] INFO starting (kafka.server.KafkaServer)
[2020-02-27 09:21:37,982] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-02-27 09:21:38,033] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-02-27 09:21:38,050] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,051] INFO Client environment:host.name=MTNB311.mitrais.com (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,051] INFO Client environment:java.version=1.8.0_31 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,052] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,053] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_31\jre (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,055] INFO Client environment:java.class.path=.;c:\java;c:\apache-tomcat-9.0.14\lib\activation.jar;c:\apache-tomcat-9.0.14\lib\commons-email-1.4.jar;c:\apache-tomcat-9.0.14\lib\commons-fileupload-1.0.jar;c:\apache-tomcat-9.0.14\lib\itext-4.2.0.jar;c:\apache-tomcat-9.0.14\lib\jcommon-1.0.23.jar;c:\apache-tomcat-9.0.14\lib\jfreechart-1.0.19.jar;c:\apache-tomcat-9.0.14\lib\json-1.1.jar;c:\apache-tomcat-9.0.14\lib\mail.jar;c:\apache-tomcat-9.0.14\lib\mysql-connector-java-3.0.10-stable-bin.jar;c:\apache-tomcat-9.0.14\lib\servlet-api.jar;c:\apache-tomcat-9.0.14\webapps\infocare\WEB-INF\classes;;C:\kafka_\libs\activation-1.1.1.jar;C:\kafka_\libs\aopalliance-repackaged-2.5.0.jar;C:\kafka_\libs\argparse4j-0.7.0.jar;C:\kafka_\libs\audience-annotations-0.5.0.jar;C:\kafka_\libs\commons-lang3-3.8.1.jar;C:\kafka_\libs\connect-api-2.3.0.jar;C:\kafka_\libs\connect-basic-auth-extension-2.3.0.jar;C:\kafka_\libs\connect-file-2.3.0.jar;C:\kafka_\libs\connect-json-2.3.0.jar;C:\kafka_\libs\connect-runtime-2.3.0.jar;C:\kafka_\libs\connect-transforms-2.3.0.jar;C:\kafka_\libs\guava-20.0.jar;C:\kafka_\libs\hk2-api-2.5.0.jar;C:\kafka_\libs\hk2-locator-2.5.0.jar;C:\kafka_\libs\hk2-utils-2.5.0.jar;C:\kafka_\libs\jackson-annotations-2.9.9.jar;C:\kafka_\libs\jackson-core-2.9.9.jar;C:\kafka_\libs\jackson-databind-2.9.9.jar;C:\kafka_\libs\jackson-dataformat-csv-2.9.9.jar;C:\kafka_\libs\jackson-datatype-jdk8-2.9.9.jar;C:\kafka_\libs\jackson-jaxrs-base-2.9.9.jar;C:\kafka_\libs\jackson-jaxrs-json-provider-2.9.9.jar;C:\kafka_\libs\jackson-module-jaxb-annotations-2.9.9.jar;C:\kafka_\libs\jackson-module-paranamer-2.9.9.jar;C:\kafka_\libs\jackson-module-scala_2.12-2.9.9.jar;C:\kafka_\libs\jakarta.annotation-api-1.3.4.jar;C:\kafka_\libs\jakarta.inject-2.5.0.jar;C:\kafka_\libs\jakarta.ws.rs-api-2.1.5.jar;C:\kafka_\libs\javassist-3.22.0-CR2.jar;C:\kafka_\libs\javax.servlet-api-3.1.0.jar;C:\kafka_\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_\libs\jaxb-api-2.3.0.jar;C:\kafka_\libs\jersey-client-2.28.jar;C:\kafka_\libs\jersey-common-2.28.jar;C:\kafka_\libs\jersey-container-servlet-2.28.jar;C:\kafka_\libs\jersey-container-servlet-core-2.28.jar;C:\kafka_\libs\jersey-hk2-2.28.jar;C:\kafka_\libs\jersey-media-jaxb-2.28.jar;C:\kafka_\libs\jersey-server-2.28.jar;C:\kafka_\libs\jetty-client-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-continuation-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-http-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-io-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-security-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-server-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-servlet-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-servlets-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-util-9.4.18.v20190429.jar;C:\kafka_\libs\jopt-simple-5.0.4.jar;C:\kafka_\libs\jsr305-3.0.2.jar;C:\kafka_\libs\kafka-clients-2.3.0.jar;C:\kafka_\libs\kafka-log4j-appender-2.3.0.jar;C:\kafka_\libs\kafka-streams-2.3.0.jar;C:\kafka_\libs\kafka-streams-examples-2.3.0.jar;C:\kafka_\libs\kafka-streams-scala_2.12-2.3.0.jar;C:\kafka_\libs\kafka-streams-test-utils-2.3.0.jar;C:\kafka_\libs\kafka-tools-2.3.0.jar;C:\kafka_\libs\kafka_2.12-2.3.0-javadoc.jar;C:\kafka_\libs\kafka_2.12-2.3.0-javadoc.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-scaladoc.jar;C:\kafka_\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-sources.jar;C:\kafka_\libs\kafka_2.12-2.3.0-sources.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-test-sources.jar;C:\kafka_\libs\kafka_2.12-2.3.0-test-sources.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-test.jar;C:\kafka_\libs\kafka_2.12-2.3.0-test.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0.jar;C:\kafka_\libs\kafka_2.12-2.3.0.jar.asc;C:\kafka_\libs\log4j-1.2.17.jar;C:\kafka_\libs\lz4-java-1.6.0.jar;C:\kafka_\libs\maven-artifact-3.6.1.jar;C:\kafka_\libs\metrics-core-2.2.0.jar;C:\kafka_\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_\libs\paranamer-2.8.jar;C:\kafka_\libs\plexus-utils-3.2.0.jar;C:\kafka_\libs\reflections-0.9.11.jar;C:\kafka_\libs\rocksdbjni-5.18.3.jar;C:\kafka_\libs\scala-library-2.12.8.jar;C:\kafka_\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_\libs\scala-reflect-2.12.8.jar;C:\kafka_\libs\slf4j-api-1.7.26.jar;C:\kafka_\libs\slf4j-log4j12-1.7.26.jar;C:\kafka_\libs\snappy-java-1.1.7.3.jar;C:\kafka_\libs\spotbugs-annotations-3.1.9.jar;C:\kafka_\libs\validation-api-2.0.1.Final.jar;C:\kafka_\libs\zkclient-0.11.jar;C:\kafka_\libs\zookeeper-3.4.14.jar;C:\kafka_\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,059] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_31\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Intel\iCLS Client\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Skype\Phone\;C:\Program Files (x86)\Microsoft SQL Server\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\apache-maven-3.6.0\bin;C:\Program Files\Git\cmd;C:\Program Files (x86)\MySQL\MySQL Fabric 1.5.3 & MySQL Utilities 1.5.3 1.5\;C:\Program Files (x86)\MySQL\MySQL Fabric 1.5.3 & MySQL Utilities 1.5.3 1.5\Doctrine extensions for PHP\;C:\Program Files (x86)\WinSCP\;C:\Users\Syarif_H657\Downloads\gradle-5.2.1\bin;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\MongoDB\Server\4.0\bin;C:\Go\bin;C:\Program Files\Java\jdk1.8.0_31\bin;;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\nodejs\;C:\Users\Syarif_H657\AppData\Local\Programs\Python\Python37-32\Scripts\;C:\Users\Syarif_H657\AppData\Local\Programs\Python\Python37-32\;C:\Users\Syarif_H657\AppData\Local\Microsoft\WindowsApps;C:\Program Files\JetBrains\IntelliJ IDEA 2018.3.4\bin;C:\Program Files\JetBrains\WebStorm 2018.3.5\bin;C:\Users\Syarif_H657\AppData\Local\Yarn\bin;C:\Program Files\JetBrains\GoLand 2019.1.3\bin;C:\Users\Syarif_H657\go\bin;C:\Users\Syarif_H657\AppData\Local\GitHubDesktop\bin;C:\Users\Syarif_H657\AppData\Local\Microsoft\WindowsApps;;f:\Atlassian\atlassian-plugin-sdk-8.0.16\bin;C:\Program Files\Haulmont\CUBA Studio 2019.1\bin;;C:\Users\Syarif_H657\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,061] INFO Client environment:java.io.tmpdir=C:\Users\SYARIF~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,062] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,062] INFO Client environment:os.name=Windows 8.1 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,063] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,066] INFO Client environment:os.version=6.3 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,067] INFO Client environment:user.name=Syarif_H657 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,068] INFO Client environment:user.home=C:\Users\Syarif_H657 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,069] INFO Client environment:user.dir=C:\kafka_\bin\windows (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,072] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2e4b8173 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:21:38,123] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-27 09:21:38,129] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-02-27 09:21:38,132] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-02-27 09:21:38,132] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:49491 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-27 09:21:38,138] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:49491 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:21:38,147] INFO Established session 0x1004716d6d10001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:49491 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:21:38,151] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1004716d6d10001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-02-27 09:21:38,160] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-27 09:21:38,249] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10001 type:create cxid:0x1 zxid:0xf9 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:21:38,702] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10001 type:create cxid:0x2 zxid:0xfa txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:21:38,709] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10001 type:create cxid:0x3 zxid:0xfb txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:21:38,714] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10001 type:create cxid:0x4 zxid:0xfc txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:21:38,718] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10001 type:create cxid:0x5 zxid:0xfd txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:21:38,721] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10001 type:create cxid:0x6 zxid:0xfe txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:21:38,725] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10001 type:create cxid:0x7 zxid:0xff txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:21:38,729] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10001 type:create cxid:0x8 zxid:0x100 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:21:38,739] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10001 type:create cxid:0x9 zxid:0x101 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:21:38,746] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10001 type:create cxid:0xa zxid:0x102 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:21:38,749] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10001 type:create cxid:0xb zxid:0x103 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:21:38,752] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10001 type:create cxid:0xc zxid:0x104 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:21:38,756] INFO Got user-level KeeperException when processing sessionid:0x1004716d6d10001 type:create cxid:0xd zxid:0x105 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:21:39,089] INFO Cluster ID = N2lSmjBdQoCizp4jp6C8fQ (kafka.server.KafkaServer)
[2020-02-27 09:21:39,279] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = c:\log
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-27 09:21:39,300] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = c:\log
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-27 09:21:39,361] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-27 09:21:39,361] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-27 09:21:39,364] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-27 09:21:39,432] INFO Loading logs. (kafka.log.LogManager)
[2020-02-27 09:21:39,544] INFO [Log partition=blog-approval-0, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:39,549] INFO [Log partition=blog-approval-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:39,670] INFO [ProducerStateManager partition=blog-approval-0] Writing producer snapshot at offset 35 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:39,739] INFO [Log partition=blog-approval-0, dir=c:\log] Loading producer state till offset 35 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:39,748] INFO [ProducerStateManager partition=blog-approval-0] Loading producer state from snapshot file 'c:\log\blog-approval-0\00000000000000000035.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:39,772] INFO [Log partition=blog-approval-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 35 in 279 ms (kafka.log.Log)
[2020-02-27 09:21:39,794] INFO [Log partition=blog-creation-0, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:39,795] INFO [Log partition=blog-creation-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:39,835] INFO [ProducerStateManager partition=blog-creation-0] Writing producer snapshot at offset 54 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:39,861] INFO [Log partition=blog-creation-0, dir=c:\log] Loading producer state till offset 54 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:39,864] INFO [ProducerStateManager partition=blog-creation-0] Loading producer state from snapshot file 'c:\log\blog-creation-0\00000000000000000054.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:39,865] INFO [Log partition=blog-creation-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 54 in 76 ms (kafka.log.Log)
[2020-02-27 09:21:39,878] INFO [Log partition=blog-key-0, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:39,878] INFO [Log partition=blog-key-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:39,898] INFO [ProducerStateManager partition=blog-key-0] Writing producer snapshot at offset 17 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:39,920] INFO [Log partition=blog-key-0, dir=c:\log] Loading producer state till offset 17 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:39,929] INFO [ProducerStateManager partition=blog-key-0] Loading producer state from snapshot file 'c:\log\blog-key-0\00000000000000000017.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:39,931] INFO [Log partition=blog-key-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 17 in 61 ms (kafka.log.Log)
[2020-02-27 09:21:39,947] INFO [Log partition=blog-notification-0, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:39,948] INFO [Log partition=blog-notification-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:39,968] INFO [ProducerStateManager partition=blog-notification-0] Writing producer snapshot at offset 22 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:39,989] INFO [Log partition=blog-notification-0, dir=c:\log] Loading producer state till offset 22 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:39,993] INFO [ProducerStateManager partition=blog-notification-0] Loading producer state from snapshot file 'c:\log\blog-notification-0\00000000000000000022.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:39,994] INFO [Log partition=blog-notification-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 22 in 56 ms (kafka.log.Log)
[2020-02-27 09:21:40,002] INFO [Log partition=__consumer_offsets-0, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,002] INFO [Log partition=__consumer_offsets-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,022] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,039] INFO [Log partition=__consumer_offsets-0, dir=c:\log] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,045] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'c:\log\__consumer_offsets-0\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,046] INFO [Log partition=__consumer_offsets-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 48 ms (kafka.log.Log)
[2020-02-27 09:21:40,054] INFO [Log partition=__consumer_offsets-1, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,055] INFO [Log partition=__consumer_offsets-1, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,075] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,092] INFO [Log partition=__consumer_offsets-1, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,096] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'c:\log\__consumer_offsets-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,097] INFO [Log partition=__consumer_offsets-1, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2020-02-27 09:21:40,105] INFO [Log partition=__consumer_offsets-10, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,106] INFO [Log partition=__consumer_offsets-10, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,128] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,144] INFO [Log partition=__consumer_offsets-10, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,147] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'c:\log\__consumer_offsets-10\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,148] INFO [Log partition=__consumer_offsets-10, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2020-02-27 09:21:40,154] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Found file c:\log\__consumer_offsets-11\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2020-02-27 09:21:40,155] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Deleting index files with suffix  for baseFile c:\log\__consumer_offsets-11\00000000000000000000.index (kafka.log.Log)
[2020-02-27 09:21:40,161] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Found file c:\log\__consumer_offsets-11\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2020-02-27 09:21:40,162] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Deleting index files with suffix  for baseFile c:\log\__consumer_offsets-11\00000000000000000000.log (kafka.log.Log)
[2020-02-27 09:21:40,166] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Deleting index files with suffix .swap for baseFile c:\log\__consumer_offsets-11\00000000000000000000.log (kafka.log.Log)
[2020-02-27 09:21:40,172] ERROR [Log partition=__consumer_offsets-11, dir=c:\log] Could not find offset index file corresponding to log file c:\log\__consumer_offsets-11\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-27 09:21:40,172] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,200] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 16 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,204] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,205] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,235] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 16 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,237] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Recovering unflushed segment 16 (kafka.log.Log)
[2020-02-27 09:21:40,238] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Loading producer state till offset 16 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,244] INFO [ProducerStateManager partition=__consumer_offsets-11] Loading producer state from snapshot file 'c:\log\__consumer_offsets-11\00000000000000000016.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,262] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 18 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,279] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Loading producer state till offset 18 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,282] INFO [ProducerStateManager partition=__consumer_offsets-11] Loading producer state from snapshot file 'c:\log\__consumer_offsets-11\00000000000000000018.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,283] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Completed load of log with 2 segments, log start offset 0 and log end offset 18 in 131 ms (kafka.log.Log)
[2020-02-27 09:21:40,295] INFO [Log partition=__consumer_offsets-12, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,295] INFO [Log partition=__consumer_offsets-12, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,316] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,338] INFO [Log partition=__consumer_offsets-12, dir=c:\log] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,343] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'c:\log\__consumer_offsets-12\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,345] INFO [Log partition=__consumer_offsets-12, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 58 ms (kafka.log.Log)
[2020-02-27 09:21:40,353] INFO [Log partition=__consumer_offsets-13, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,354] INFO [Log partition=__consumer_offsets-13, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,379] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,397] INFO [Log partition=__consumer_offsets-13, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,400] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'c:\log\__consumer_offsets-13\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,400] INFO [Log partition=__consumer_offsets-13, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 51 ms (kafka.log.Log)
[2020-02-27 09:21:40,408] INFO [Log partition=__consumer_offsets-14, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,411] INFO [Log partition=__consumer_offsets-14, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,432] INFO [ProducerStateManager partition=__consumer_offsets-14] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,449] INFO [Log partition=__consumer_offsets-14, dir=c:\log] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,451] INFO [ProducerStateManager partition=__consumer_offsets-14] Loading producer state from snapshot file 'c:\log\__consumer_offsets-14\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,452] INFO [Log partition=__consumer_offsets-14, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 49 ms (kafka.log.Log)
[2020-02-27 09:21:40,462] INFO [Log partition=__consumer_offsets-15, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,462] INFO [Log partition=__consumer_offsets-15, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,482] INFO [ProducerStateManager partition=__consumer_offsets-15] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,502] INFO [Log partition=__consumer_offsets-15, dir=c:\log] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,505] INFO [ProducerStateManager partition=__consumer_offsets-15] Loading producer state from snapshot file 'c:\log\__consumer_offsets-15\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,506] INFO [Log partition=__consumer_offsets-15, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 12 in 51 ms (kafka.log.Log)
[2020-02-27 09:21:40,517] INFO [Log partition=__consumer_offsets-16, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,518] INFO [Log partition=__consumer_offsets-16, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,536] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,556] INFO [Log partition=__consumer_offsets-16, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,563] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'c:\log\__consumer_offsets-16\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,564] INFO [Log partition=__consumer_offsets-16, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 51 ms (kafka.log.Log)
[2020-02-27 09:21:40,572] INFO [Log partition=__consumer_offsets-17, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,576] INFO [Log partition=__consumer_offsets-17, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,601] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,622] INFO [Log partition=__consumer_offsets-17, dir=c:\log] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,628] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'c:\log\__consumer_offsets-17\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,629] INFO [Log partition=__consumer_offsets-17, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 62 ms (kafka.log.Log)
[2020-02-27 09:21:40,636] INFO [Log partition=__consumer_offsets-18, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,638] INFO [Log partition=__consumer_offsets-18, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,659] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 13 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,678] INFO [Log partition=__consumer_offsets-18, dir=c:\log] Loading producer state till offset 13 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,682] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'c:\log\__consumer_offsets-18\00000000000000000013.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,682] INFO [Log partition=__consumer_offsets-18, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 13 in 50 ms (kafka.log.Log)
[2020-02-27 09:21:40,692] INFO [Log partition=__consumer_offsets-19, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,694] INFO [Log partition=__consumer_offsets-19, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,716] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,737] INFO [Log partition=__consumer_offsets-19, dir=c:\log] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,739] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file 'c:\log\__consumer_offsets-19\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,741] INFO [Log partition=__consumer_offsets-19, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 12 in 55 ms (kafka.log.Log)
[2020-02-27 09:21:40,750] INFO [Log partition=__consumer_offsets-2, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,751] INFO [Log partition=__consumer_offsets-2, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,772] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,790] INFO [Log partition=__consumer_offsets-2, dir=c:\log] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,795] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'c:\log\__consumer_offsets-2\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,796] INFO [Log partition=__consumer_offsets-2, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 49 ms (kafka.log.Log)
[2020-02-27 09:21:40,803] INFO [Log partition=__consumer_offsets-20, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,804] INFO [Log partition=__consumer_offsets-20, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,826] INFO [ProducerStateManager partition=__consumer_offsets-20] Writing producer snapshot at offset 33 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,846] INFO [Log partition=__consumer_offsets-20, dir=c:\log] Loading producer state till offset 33 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,849] INFO [ProducerStateManager partition=__consumer_offsets-20] Loading producer state from snapshot file 'c:\log\__consumer_offsets-20\00000000000000000033.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,850] INFO [Log partition=__consumer_offsets-20, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 33 in 51 ms (kafka.log.Log)
[2020-02-27 09:21:40,863] INFO [Log partition=__consumer_offsets-21, dir=c:\log] Recovering unflushed segment 47 (kafka.log.Log)
[2020-02-27 09:21:40,864] INFO [Log partition=__consumer_offsets-21, dir=c:\log] Loading producer state till offset 47 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,867] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'c:\log\__consumer_offsets-21\00000000000000000047.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,887] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 49 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,906] INFO [Log partition=__consumer_offsets-21, dir=c:\log] Loading producer state till offset 49 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,912] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'c:\log\__consumer_offsets-21\00000000000000000049.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,913] INFO [Log partition=__consumer_offsets-21, dir=c:\log] Completed load of log with 2 segments, log start offset 0 and log end offset 49 in 61 ms (kafka.log.Log)
[2020-02-27 09:21:40,921] INFO [Log partition=__consumer_offsets-22, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,922] INFO [Log partition=__consumer_offsets-22, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,945] INFO [ProducerStateManager partition=__consumer_offsets-22] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,962] INFO [Log partition=__consumer_offsets-22, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,964] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'c:\log\__consumer_offsets-22\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:40,965] INFO [Log partition=__consumer_offsets-22, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 48 ms (kafka.log.Log)
[2020-02-27 09:21:40,970] INFO [Log partition=__consumer_offsets-23, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:40,971] INFO [Log partition=__consumer_offsets-23, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:40,994] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,015] INFO [Log partition=__consumer_offsets-23, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,018] INFO [ProducerStateManager partition=__consumer_offsets-23] Loading producer state from snapshot file 'c:\log\__consumer_offsets-23\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,019] INFO [Log partition=__consumer_offsets-23, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 52 ms (kafka.log.Log)
[2020-02-27 09:21:41,027] INFO [Log partition=__consumer_offsets-24, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,028] INFO [Log partition=__consumer_offsets-24, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,047] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,063] INFO [Log partition=__consumer_offsets-24, dir=c:\log] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,065] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'c:\log\__consumer_offsets-24\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,066] INFO [Log partition=__consumer_offsets-24, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 45 ms (kafka.log.Log)
[2020-02-27 09:21:41,075] INFO [Log partition=__consumer_offsets-25, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,077] INFO [Log partition=__consumer_offsets-25, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,097] INFO [ProducerStateManager partition=__consumer_offsets-25] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,114] INFO [Log partition=__consumer_offsets-25, dir=c:\log] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,117] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file 'c:\log\__consumer_offsets-25\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,118] INFO [Log partition=__consumer_offsets-25, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 49 ms (kafka.log.Log)
[2020-02-27 09:21:41,125] INFO [Log partition=__consumer_offsets-26, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,128] INFO [Log partition=__consumer_offsets-26, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,147] INFO [ProducerStateManager partition=__consumer_offsets-26] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,163] INFO [Log partition=__consumer_offsets-26, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,165] INFO [ProducerStateManager partition=__consumer_offsets-26] Loading producer state from snapshot file 'c:\log\__consumer_offsets-26\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,166] INFO [Log partition=__consumer_offsets-26, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 46 ms (kafka.log.Log)
[2020-02-27 09:21:41,173] INFO [Log partition=__consumer_offsets-27, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,175] INFO [Log partition=__consumer_offsets-27, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,195] INFO [ProducerStateManager partition=__consumer_offsets-27] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,218] INFO [Log partition=__consumer_offsets-27, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,221] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'c:\log\__consumer_offsets-27\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,221] INFO [Log partition=__consumer_offsets-27, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 52 ms (kafka.log.Log)
[2020-02-27 09:21:41,231] INFO [Log partition=__consumer_offsets-28, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,232] INFO [Log partition=__consumer_offsets-28, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,253] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 36 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,267] INFO [Log partition=__consumer_offsets-28, dir=c:\log] Loading producer state till offset 36 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,269] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'c:\log\__consumer_offsets-28\00000000000000000036.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,270] INFO [Log partition=__consumer_offsets-28, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 36 in 43 ms (kafka.log.Log)
[2020-02-27 09:21:41,281] INFO [Log partition=__consumer_offsets-29, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,281] INFO [Log partition=__consumer_offsets-29, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,305] INFO [ProducerStateManager partition=__consumer_offsets-29] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,325] INFO [Log partition=__consumer_offsets-29, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,329] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file 'c:\log\__consumer_offsets-29\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,330] INFO [Log partition=__consumer_offsets-29, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 56 ms (kafka.log.Log)
[2020-02-27 09:21:41,339] INFO [Log partition=__consumer_offsets-3, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,340] INFO [Log partition=__consumer_offsets-3, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,384] INFO [Log partition=__consumer_offsets-3, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,389] INFO [Log partition=__consumer_offsets-3, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2020-02-27 09:21:41,400] INFO [Log partition=__consumer_offsets-30, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,401] INFO [Log partition=__consumer_offsets-30, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,421] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,450] INFO [Log partition=__consumer_offsets-30, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,454] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file 'c:\log\__consumer_offsets-30\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,457] INFO [Log partition=__consumer_offsets-30, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 62 ms (kafka.log.Log)
[2020-02-27 09:21:41,475] INFO [Log partition=__consumer_offsets-31, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,477] INFO [Log partition=__consumer_offsets-31, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,497] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,516] INFO [Log partition=__consumer_offsets-31, dir=c:\log] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,518] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'c:\log\__consumer_offsets-31\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,519] INFO [Log partition=__consumer_offsets-31, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 52 ms (kafka.log.Log)
[2020-02-27 09:21:41,528] INFO [Log partition=__consumer_offsets-32, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,529] INFO [Log partition=__consumer_offsets-32, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,548] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,564] INFO [Log partition=__consumer_offsets-32, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,567] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'c:\log\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,568] INFO [Log partition=__consumer_offsets-32, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2020-02-27 09:21:41,583] INFO [Log partition=__consumer_offsets-33, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,584] INFO [Log partition=__consumer_offsets-33, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,605] INFO [ProducerStateManager partition=__consumer_offsets-33] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,631] INFO [Log partition=__consumer_offsets-33, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,635] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file 'c:\log\__consumer_offsets-33\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,637] INFO [Log partition=__consumer_offsets-33, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 63 ms (kafka.log.Log)
[2020-02-27 09:21:41,650] INFO [Log partition=__consumer_offsets-34, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,650] INFO [Log partition=__consumer_offsets-34, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,670] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,693] INFO [Log partition=__consumer_offsets-34, dir=c:\log] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,696] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'c:\log\__consumer_offsets-34\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,697] INFO [Log partition=__consumer_offsets-34, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 54 ms (kafka.log.Log)
[2020-02-27 09:21:41,701] INFO [Log partition=__consumer_offsets-35, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,701] INFO [Log partition=__consumer_offsets-35, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,728] INFO [Log partition=__consumer_offsets-35, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,731] INFO [Log partition=__consumer_offsets-35, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2020-02-27 09:21:41,736] INFO [Log partition=__consumer_offsets-36, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,736] INFO [Log partition=__consumer_offsets-36, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,765] INFO [Log partition=__consumer_offsets-36, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,767] INFO [Log partition=__consumer_offsets-36, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2020-02-27 09:21:41,772] INFO [Log partition=__consumer_offsets-37, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,772] INFO [Log partition=__consumer_offsets-37, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,796] INFO [ProducerStateManager partition=__consumer_offsets-37] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,814] INFO [Log partition=__consumer_offsets-37, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,817] INFO [ProducerStateManager partition=__consumer_offsets-37] Loading producer state from snapshot file 'c:\log\__consumer_offsets-37\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,818] INFO [Log partition=__consumer_offsets-37, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 49 ms (kafka.log.Log)
[2020-02-27 09:21:41,823] INFO [Log partition=__consumer_offsets-38, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,825] INFO [Log partition=__consumer_offsets-38, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,846] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,864] INFO [Log partition=__consumer_offsets-38, dir=c:\log] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,866] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'c:\log\__consumer_offsets-38\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,867] INFO [Log partition=__consumer_offsets-38, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 48 ms (kafka.log.Log)
[2020-02-27 09:21:41,873] INFO [Log partition=__consumer_offsets-39, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,875] INFO [Log partition=__consumer_offsets-39, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,895] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,911] INFO [Log partition=__consumer_offsets-39, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,914] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'c:\log\__consumer_offsets-39\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:41,915] INFO [Log partition=__consumer_offsets-39, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 46 ms (kafka.log.Log)
[2020-02-27 09:21:41,920] INFO [Log partition=__consumer_offsets-4, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,921] INFO [Log partition=__consumer_offsets-4, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,950] INFO [Log partition=__consumer_offsets-4, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,953] INFO [Log partition=__consumer_offsets-4, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2020-02-27 09:21:41,961] INFO [Log partition=__consumer_offsets-40, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:41,962] INFO [Log partition=__consumer_offsets-40, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:41,982] INFO [ProducerStateManager partition=__consumer_offsets-40] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,003] INFO [Log partition=__consumer_offsets-40, dir=c:\log] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,011] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'c:\log\__consumer_offsets-40\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,013] INFO [Log partition=__consumer_offsets-40, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 59 ms (kafka.log.Log)
[2020-02-27 09:21:42,021] INFO [Log partition=__consumer_offsets-41, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:42,022] INFO [Log partition=__consumer_offsets-41, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,044] INFO [ProducerStateManager partition=__consumer_offsets-41] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,058] INFO [Log partition=__consumer_offsets-41, dir=c:\log] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,062] INFO [ProducerStateManager partition=__consumer_offsets-41] Loading producer state from snapshot file 'c:\log\__consumer_offsets-41\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,063] INFO [Log partition=__consumer_offsets-41, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 46 ms (kafka.log.Log)
[2020-02-27 09:21:42,069] INFO [Log partition=__consumer_offsets-42, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:42,069] INFO [Log partition=__consumer_offsets-42, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,091] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,108] INFO [Log partition=__consumer_offsets-42, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,112] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file 'c:\log\__consumer_offsets-42\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,113] INFO [Log partition=__consumer_offsets-42, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 48 ms (kafka.log.Log)
[2020-02-27 09:21:42,119] INFO [Log partition=__consumer_offsets-43, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:42,120] INFO [Log partition=__consumer_offsets-43, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,137] INFO [ProducerStateManager partition=__consumer_offsets-43] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,155] INFO [Log partition=__consumer_offsets-43, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,159] INFO [ProducerStateManager partition=__consumer_offsets-43] Loading producer state from snapshot file 'c:\log\__consumer_offsets-43\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,160] INFO [Log partition=__consumer_offsets-43, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 45 ms (kafka.log.Log)
[2020-02-27 09:21:42,166] INFO [Log partition=__consumer_offsets-44, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:42,167] INFO [Log partition=__consumer_offsets-44, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,186] INFO [ProducerStateManager partition=__consumer_offsets-44] Writing producer snapshot at offset 23 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,204] INFO [Log partition=__consumer_offsets-44, dir=c:\log] Loading producer state till offset 23 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,206] INFO [ProducerStateManager partition=__consumer_offsets-44] Loading producer state from snapshot file 'c:\log\__consumer_offsets-44\00000000000000000023.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,208] INFO [Log partition=__consumer_offsets-44, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 23 in 46 ms (kafka.log.Log)
[2020-02-27 09:21:42,215] INFO [Log partition=__consumer_offsets-45, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:42,216] INFO [Log partition=__consumer_offsets-45, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,234] INFO [ProducerStateManager partition=__consumer_offsets-45] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,252] INFO [Log partition=__consumer_offsets-45, dir=c:\log] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,254] INFO [ProducerStateManager partition=__consumer_offsets-45] Loading producer state from snapshot file 'c:\log\__consumer_offsets-45\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,255] INFO [Log partition=__consumer_offsets-45, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 12 in 44 ms (kafka.log.Log)
[2020-02-27 09:21:42,263] INFO [Log partition=__consumer_offsets-46, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:42,264] INFO [Log partition=__consumer_offsets-46, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,283] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,299] INFO [Log partition=__consumer_offsets-46, dir=c:\log] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,301] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'c:\log\__consumer_offsets-46\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,301] INFO [Log partition=__consumer_offsets-46, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 43 ms (kafka.log.Log)
[2020-02-27 09:21:42,310] INFO [Log partition=__consumer_offsets-47, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:42,311] INFO [Log partition=__consumer_offsets-47, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,330] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,345] INFO [Log partition=__consumer_offsets-47, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,348] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'c:\log\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,348] INFO [Log partition=__consumer_offsets-47, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 44 ms (kafka.log.Log)
[2020-02-27 09:21:42,353] INFO [Log partition=__consumer_offsets-48, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:42,354] INFO [Log partition=__consumer_offsets-48, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,371] INFO [ProducerStateManager partition=__consumer_offsets-48] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,388] INFO [Log partition=__consumer_offsets-48, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,390] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file 'c:\log\__consumer_offsets-48\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,393] INFO [Log partition=__consumer_offsets-48, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 43 ms (kafka.log.Log)
[2020-02-27 09:21:42,400] INFO [Log partition=__consumer_offsets-49, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:42,401] INFO [Log partition=__consumer_offsets-49, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,418] INFO [ProducerStateManager partition=__consumer_offsets-49] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,434] INFO [Log partition=__consumer_offsets-49, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,436] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file 'c:\log\__consumer_offsets-49\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,437] INFO [Log partition=__consumer_offsets-49, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 41 ms (kafka.log.Log)
[2020-02-27 09:21:42,445] INFO [Log partition=__consumer_offsets-5, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:42,446] INFO [Log partition=__consumer_offsets-5, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,463] INFO [ProducerStateManager partition=__consumer_offsets-5] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,478] INFO [Log partition=__consumer_offsets-5, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,481] INFO [ProducerStateManager partition=__consumer_offsets-5] Loading producer state from snapshot file 'c:\log\__consumer_offsets-5\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,482] INFO [Log partition=__consumer_offsets-5, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 43 ms (kafka.log.Log)
[2020-02-27 09:21:42,486] INFO [Log partition=__consumer_offsets-6, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:42,487] INFO [Log partition=__consumer_offsets-6, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,516] INFO [Log partition=__consumer_offsets-6, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,518] INFO [Log partition=__consumer_offsets-6, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2020-02-27 09:21:42,524] INFO [Log partition=__consumer_offsets-7, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:42,525] INFO [Log partition=__consumer_offsets-7, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,545] INFO [ProducerStateManager partition=__consumer_offsets-7] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,561] INFO [Log partition=__consumer_offsets-7, dir=c:\log] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,563] INFO [ProducerStateManager partition=__consumer_offsets-7] Loading producer state from snapshot file 'c:\log\__consumer_offsets-7\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,564] INFO [Log partition=__consumer_offsets-7, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 44 ms (kafka.log.Log)
[2020-02-27 09:21:42,570] INFO [Log partition=__consumer_offsets-8, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:42,570] INFO [Log partition=__consumer_offsets-8, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,595] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,611] INFO [Log partition=__consumer_offsets-8, dir=c:\log] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,613] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'c:\log\__consumer_offsets-8\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-27 09:21:42,614] INFO [Log partition=__consumer_offsets-8, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 48 ms (kafka.log.Log)
[2020-02-27 09:21:42,619] INFO [Log partition=__consumer_offsets-9, dir=c:\log] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-27 09:21:42,619] INFO [Log partition=__consumer_offsets-9, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,644] INFO [Log partition=__consumer_offsets-9, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:21:42,647] INFO [Log partition=__consumer_offsets-9, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-02-27 09:21:42,651] INFO Logs loading complete in 3219 ms. (kafka.log.LogManager)
[2020-02-27 09:21:42,678] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-02-27 09:21:42,680] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-02-27 09:21:43,100] ERROR Failed to clean up log for __consumer_offsets-21 in dir c:\log due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: c:\log\__consumer_offsets-21\00000000000000000000.timeindex.cleaned -> c:\log\__consumer_offsets-21\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2016)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2016)
	at kafka.log.Log$$Lambda$400/1499287165.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2016)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at kafka.log.Cleaner$$Lambda$369/146291267.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: c:\log\__consumer_offsets-21\00000000000000000000.timeindex.cleaned -> c:\log\__consumer_offsets-21\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 18 more
[2020-02-27 09:21:43,231] ERROR Failed to clean up log for __consumer_offsets-21 in dir c:\log due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: c:\log\__consumer_offsets-21\00000000000000000000.timeindex.cleaned -> c:\log\__consumer_offsets-21\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2016)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2016)
	at kafka.log.Log$$Lambda$400/1499287165.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2016)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at kafka.log.Cleaner$$Lambda$369/146291267.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: c:\log\__consumer_offsets-21\00000000000000000000.timeindex.cleaned -> c:\log\__consumer_offsets-21\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 18 more
[2020-02-27 09:21:43,267] ERROR Failed to clean up log for __consumer_offsets-21 in dir c:\log due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: c:\log\__consumer_offsets-21\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at kafka.log.Cleaner$$Lambda$369/146291267.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2020-02-27 09:21:43,304] ERROR Failed to clean up log for __consumer_offsets-21 in dir c:\log due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: c:\log\__consumer_offsets-21\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at kafka.log.Cleaner$$Lambda$369/146291267.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2020-02-27 09:21:43,350] ERROR Failed to clean up log for __consumer_offsets-21 in dir c:\log due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: c:\log\__consumer_offsets-21\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at kafka.log.Cleaner$$Lambda$369/146291267.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2020-02-27 09:21:43,408] ERROR Failed to clean up log for __consumer_offsets-21 in dir c:\log due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: c:\log\__consumer_offsets-21\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at kafka.log.Cleaner$$Lambda$369/146291267.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2020-02-27 09:21:43,470] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2020-02-27 09:21:43,472] ERROR Failed to clean up log for __consumer_offsets-21 in dir c:\log due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: c:\log\__consumer_offsets-21\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at kafka.log.Cleaner$$Lambda$369/146291267.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2020-02-27 09:21:43,510] ERROR Failed to clean up log for __consumer_offsets-21 in dir c:\log due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: c:\log\__consumer_offsets-21\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at kafka.log.Cleaner$$Lambda$369/146291267.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2020-02-27 09:21:43,595] ERROR Failed to clean up log for __consumer_offsets-21 in dir c:\log due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: c:\log\__consumer_offsets-21\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at kafka.log.Cleaner$$Lambda$369/146291267.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2020-02-27 09:21:43,604] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-02-27 09:21:43,613] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-02-27 09:21:43,671] ERROR Failed to clean up log for __consumer_offsets-21 in dir c:\log due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: c:\log\__consumer_offsets-21\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at kafka.log.Cleaner$$Lambda$369/146291267.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2020-02-27 09:21:43,720] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 09:21:43,722] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 09:21:43,721] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 09:21:43,721] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 09:21:43,787] ERROR Failed to clean up log for __consumer_offsets-21 in dir c:\log due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: c:\log\__consumer_offsets-21\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at kafka.log.Cleaner$$Lambda$369/146291267.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2020-02-27 09:21:43,796] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-02-27 09:21:43,801] INFO [ReplicaManager broker=0] Stopping serving replicas in dir c:\log (kafka.server.ReplicaManager)
[2020-02-27 09:21:43,818] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory c:\log. (kafka.server.ReplicaManager)
[2020-02-27 09:21:43,827] INFO Stopping serving logs in dir c:\log (kafka.log.LogManager)
[2020-02-27 09:21:43,839] ERROR Shutdown broker because all log dirs in c:\log have failed (kafka.log.LogManager)
[2020-02-27 09:21:44,188] WARN Exception causing close of session 0x1004716d6d10001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-27 09:21:44,189] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:49491 which had sessionid 0x1004716d6d10001 (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-27 09:22:24,717] INFO Reading configuration from: c:\kafka_\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-02-27 09:22:24,727] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-27 09:22:24,727] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-27 09:22:24,728] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-27 09:22:24,730] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-02-27 09:22:24,809] INFO Reading configuration from: c:\kafka_\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-02-27 09:22:24,810] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-02-27 09:22:24,858] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,858] INFO Server environment:host.name=MTNB311.mitrais.com (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,860] INFO Server environment:java.version=1.8.0_31 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,861] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,862] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_31\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,863] INFO Server environment:java.class.path=.;c:\java;c:\apache-tomcat-9.0.14\lib\activation.jar;c:\apache-tomcat-9.0.14\lib\commons-email-1.4.jar;c:\apache-tomcat-9.0.14\lib\commons-fileupload-1.0.jar;c:\apache-tomcat-9.0.14\lib\itext-4.2.0.jar;c:\apache-tomcat-9.0.14\lib\jcommon-1.0.23.jar;c:\apache-tomcat-9.0.14\lib\jfreechart-1.0.19.jar;c:\apache-tomcat-9.0.14\lib\json-1.1.jar;c:\apache-tomcat-9.0.14\lib\mail.jar;c:\apache-tomcat-9.0.14\lib\mysql-connector-java-3.0.10-stable-bin.jar;c:\apache-tomcat-9.0.14\lib\servlet-api.jar;c:\apache-tomcat-9.0.14\webapps\infocare\WEB-INF\classes;;C:\kafka_\libs\activation-1.1.1.jar;C:\kafka_\libs\aopalliance-repackaged-2.5.0.jar;C:\kafka_\libs\argparse4j-0.7.0.jar;C:\kafka_\libs\audience-annotations-0.5.0.jar;C:\kafka_\libs\commons-lang3-3.8.1.jar;C:\kafka_\libs\connect-api-2.3.0.jar;C:\kafka_\libs\connect-basic-auth-extension-2.3.0.jar;C:\kafka_\libs\connect-file-2.3.0.jar;C:\kafka_\libs\connect-json-2.3.0.jar;C:\kafka_\libs\connect-runtime-2.3.0.jar;C:\kafka_\libs\connect-transforms-2.3.0.jar;C:\kafka_\libs\guava-20.0.jar;C:\kafka_\libs\hk2-api-2.5.0.jar;C:\kafka_\libs\hk2-locator-2.5.0.jar;C:\kafka_\libs\hk2-utils-2.5.0.jar;C:\kafka_\libs\jackson-annotations-2.9.9.jar;C:\kafka_\libs\jackson-core-2.9.9.jar;C:\kafka_\libs\jackson-databind-2.9.9.jar;C:\kafka_\libs\jackson-dataformat-csv-2.9.9.jar;C:\kafka_\libs\jackson-datatype-jdk8-2.9.9.jar;C:\kafka_\libs\jackson-jaxrs-base-2.9.9.jar;C:\kafka_\libs\jackson-jaxrs-json-provider-2.9.9.jar;C:\kafka_\libs\jackson-module-jaxb-annotations-2.9.9.jar;C:\kafka_\libs\jackson-module-paranamer-2.9.9.jar;C:\kafka_\libs\jackson-module-scala_2.12-2.9.9.jar;C:\kafka_\libs\jakarta.annotation-api-1.3.4.jar;C:\kafka_\libs\jakarta.inject-2.5.0.jar;C:\kafka_\libs\jakarta.ws.rs-api-2.1.5.jar;C:\kafka_\libs\javassist-3.22.0-CR2.jar;C:\kafka_\libs\javax.servlet-api-3.1.0.jar;C:\kafka_\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_\libs\jaxb-api-2.3.0.jar;C:\kafka_\libs\jersey-client-2.28.jar;C:\kafka_\libs\jersey-common-2.28.jar;C:\kafka_\libs\jersey-container-servlet-2.28.jar;C:\kafka_\libs\jersey-container-servlet-core-2.28.jar;C:\kafka_\libs\jersey-hk2-2.28.jar;C:\kafka_\libs\jersey-media-jaxb-2.28.jar;C:\kafka_\libs\jersey-server-2.28.jar;C:\kafka_\libs\jetty-client-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-continuation-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-http-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-io-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-security-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-server-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-servlet-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-servlets-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-util-9.4.18.v20190429.jar;C:\kafka_\libs\jopt-simple-5.0.4.jar;C:\kafka_\libs\jsr305-3.0.2.jar;C:\kafka_\libs\kafka-clients-2.3.0.jar;C:\kafka_\libs\kafka-log4j-appender-2.3.0.jar;C:\kafka_\libs\kafka-streams-2.3.0.jar;C:\kafka_\libs\kafka-streams-examples-2.3.0.jar;C:\kafka_\libs\kafka-streams-scala_2.12-2.3.0.jar;C:\kafka_\libs\kafka-streams-test-utils-2.3.0.jar;C:\kafka_\libs\kafka-tools-2.3.0.jar;C:\kafka_\libs\kafka_2.12-2.3.0-javadoc.jar;C:\kafka_\libs\kafka_2.12-2.3.0-javadoc.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-scaladoc.jar;C:\kafka_\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-sources.jar;C:\kafka_\libs\kafka_2.12-2.3.0-sources.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-test-sources.jar;C:\kafka_\libs\kafka_2.12-2.3.0-test-sources.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-test.jar;C:\kafka_\libs\kafka_2.12-2.3.0-test.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0.jar;C:\kafka_\libs\kafka_2.12-2.3.0.jar.asc;C:\kafka_\libs\log4j-1.2.17.jar;C:\kafka_\libs\lz4-java-1.6.0.jar;C:\kafka_\libs\maven-artifact-3.6.1.jar;C:\kafka_\libs\metrics-core-2.2.0.jar;C:\kafka_\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_\libs\paranamer-2.8.jar;C:\kafka_\libs\plexus-utils-3.2.0.jar;C:\kafka_\libs\reflections-0.9.11.jar;C:\kafka_\libs\rocksdbjni-5.18.3.jar;C:\kafka_\libs\scala-library-2.12.8.jar;C:\kafka_\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_\libs\scala-reflect-2.12.8.jar;C:\kafka_\libs\slf4j-api-1.7.26.jar;C:\kafka_\libs\slf4j-log4j12-1.7.26.jar;C:\kafka_\libs\snappy-java-1.1.7.3.jar;C:\kafka_\libs\spotbugs-annotations-3.1.9.jar;C:\kafka_\libs\validation-api-2.0.1.Final.jar;C:\kafka_\libs\zkclient-0.11.jar;C:\kafka_\libs\zookeeper-3.4.14.jar;C:\kafka_\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,866] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_31\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Intel\iCLS Client\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Skype\Phone\;C:\Program Files (x86)\Microsoft SQL Server\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\apache-maven-3.6.0\bin;C:\Program Files\Git\cmd;C:\Program Files (x86)\MySQL\MySQL Fabric 1.5.3 & MySQL Utilities 1.5.3 1.5\;C:\Program Files (x86)\MySQL\MySQL Fabric 1.5.3 & MySQL Utilities 1.5.3 1.5\Doctrine extensions for PHP\;C:\Program Files (x86)\WinSCP\;C:\Users\Syarif_H657\Downloads\gradle-5.2.1\bin;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\MongoDB\Server\4.0\bin;C:\Go\bin;C:\Program Files\Java\jdk1.8.0_31\bin;;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\nodejs\;C:\Users\Syarif_H657\AppData\Local\Programs\Python\Python37-32\Scripts\;C:\Users\Syarif_H657\AppData\Local\Programs\Python\Python37-32\;C:\Users\Syarif_H657\AppData\Local\Microsoft\WindowsApps;C:\Program Files\JetBrains\IntelliJ IDEA 2018.3.4\bin;C:\Program Files\JetBrains\WebStorm 2018.3.5\bin;C:\Users\Syarif_H657\AppData\Local\Yarn\bin;C:\Program Files\JetBrains\GoLand 2019.1.3\bin;C:\Users\Syarif_H657\go\bin;C:\Users\Syarif_H657\AppData\Local\GitHubDesktop\bin;C:\Users\Syarif_H657\AppData\Local\Microsoft\WindowsApps;;f:\Atlassian\atlassian-plugin-sdk-8.0.16\bin;C:\Program Files\Haulmont\CUBA Studio 2019.1\bin;;C:\Users\Syarif_H657\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,871] INFO Server environment:java.io.tmpdir=C:\Users\SYARIF~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,873] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,874] INFO Server environment:os.name=Windows 8.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,875] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,876] INFO Server environment:os.version=6.3 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,876] INFO Server environment:user.name=Syarif_H657 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,877] INFO Server environment:user.home=C:\Users\Syarif_H657 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,878] INFO Server environment:user.dir=C:\kafka_\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,904] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,904] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:24,906] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:25,004] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-02-27 09:22:25,007] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-27 09:22:30,247] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-02-27 09:22:31,365] INFO starting (kafka.server.KafkaServer)
[2020-02-27 09:22:31,367] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-02-27 09:22:31,421] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-02-27 09:22:31,434] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,434] INFO Client environment:host.name=MTNB311.mitrais.com (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,436] INFO Client environment:java.version=1.8.0_31 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,437] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,438] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_31\jre (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,439] INFO Client environment:java.class.path=.;c:\java;c:\apache-tomcat-9.0.14\lib\activation.jar;c:\apache-tomcat-9.0.14\lib\commons-email-1.4.jar;c:\apache-tomcat-9.0.14\lib\commons-fileupload-1.0.jar;c:\apache-tomcat-9.0.14\lib\itext-4.2.0.jar;c:\apache-tomcat-9.0.14\lib\jcommon-1.0.23.jar;c:\apache-tomcat-9.0.14\lib\jfreechart-1.0.19.jar;c:\apache-tomcat-9.0.14\lib\json-1.1.jar;c:\apache-tomcat-9.0.14\lib\mail.jar;c:\apache-tomcat-9.0.14\lib\mysql-connector-java-3.0.10-stable-bin.jar;c:\apache-tomcat-9.0.14\lib\servlet-api.jar;c:\apache-tomcat-9.0.14\webapps\infocare\WEB-INF\classes;;C:\kafka_\libs\activation-1.1.1.jar;C:\kafka_\libs\aopalliance-repackaged-2.5.0.jar;C:\kafka_\libs\argparse4j-0.7.0.jar;C:\kafka_\libs\audience-annotations-0.5.0.jar;C:\kafka_\libs\commons-lang3-3.8.1.jar;C:\kafka_\libs\connect-api-2.3.0.jar;C:\kafka_\libs\connect-basic-auth-extension-2.3.0.jar;C:\kafka_\libs\connect-file-2.3.0.jar;C:\kafka_\libs\connect-json-2.3.0.jar;C:\kafka_\libs\connect-runtime-2.3.0.jar;C:\kafka_\libs\connect-transforms-2.3.0.jar;C:\kafka_\libs\guava-20.0.jar;C:\kafka_\libs\hk2-api-2.5.0.jar;C:\kafka_\libs\hk2-locator-2.5.0.jar;C:\kafka_\libs\hk2-utils-2.5.0.jar;C:\kafka_\libs\jackson-annotations-2.9.9.jar;C:\kafka_\libs\jackson-core-2.9.9.jar;C:\kafka_\libs\jackson-databind-2.9.9.jar;C:\kafka_\libs\jackson-dataformat-csv-2.9.9.jar;C:\kafka_\libs\jackson-datatype-jdk8-2.9.9.jar;C:\kafka_\libs\jackson-jaxrs-base-2.9.9.jar;C:\kafka_\libs\jackson-jaxrs-json-provider-2.9.9.jar;C:\kafka_\libs\jackson-module-jaxb-annotations-2.9.9.jar;C:\kafka_\libs\jackson-module-paranamer-2.9.9.jar;C:\kafka_\libs\jackson-module-scala_2.12-2.9.9.jar;C:\kafka_\libs\jakarta.annotation-api-1.3.4.jar;C:\kafka_\libs\jakarta.inject-2.5.0.jar;C:\kafka_\libs\jakarta.ws.rs-api-2.1.5.jar;C:\kafka_\libs\javassist-3.22.0-CR2.jar;C:\kafka_\libs\javax.servlet-api-3.1.0.jar;C:\kafka_\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_\libs\jaxb-api-2.3.0.jar;C:\kafka_\libs\jersey-client-2.28.jar;C:\kafka_\libs\jersey-common-2.28.jar;C:\kafka_\libs\jersey-container-servlet-2.28.jar;C:\kafka_\libs\jersey-container-servlet-core-2.28.jar;C:\kafka_\libs\jersey-hk2-2.28.jar;C:\kafka_\libs\jersey-media-jaxb-2.28.jar;C:\kafka_\libs\jersey-server-2.28.jar;C:\kafka_\libs\jetty-client-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-continuation-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-http-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-io-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-security-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-server-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-servlet-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-servlets-9.4.18.v20190429.jar;C:\kafka_\libs\jetty-util-9.4.18.v20190429.jar;C:\kafka_\libs\jopt-simple-5.0.4.jar;C:\kafka_\libs\jsr305-3.0.2.jar;C:\kafka_\libs\kafka-clients-2.3.0.jar;C:\kafka_\libs\kafka-log4j-appender-2.3.0.jar;C:\kafka_\libs\kafka-streams-2.3.0.jar;C:\kafka_\libs\kafka-streams-examples-2.3.0.jar;C:\kafka_\libs\kafka-streams-scala_2.12-2.3.0.jar;C:\kafka_\libs\kafka-streams-test-utils-2.3.0.jar;C:\kafka_\libs\kafka-tools-2.3.0.jar;C:\kafka_\libs\kafka_2.12-2.3.0-javadoc.jar;C:\kafka_\libs\kafka_2.12-2.3.0-javadoc.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-scaladoc.jar;C:\kafka_\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-sources.jar;C:\kafka_\libs\kafka_2.12-2.3.0-sources.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-test-sources.jar;C:\kafka_\libs\kafka_2.12-2.3.0-test-sources.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0-test.jar;C:\kafka_\libs\kafka_2.12-2.3.0-test.jar.asc;C:\kafka_\libs\kafka_2.12-2.3.0.jar;C:\kafka_\libs\kafka_2.12-2.3.0.jar.asc;C:\kafka_\libs\log4j-1.2.17.jar;C:\kafka_\libs\lz4-java-1.6.0.jar;C:\kafka_\libs\maven-artifact-3.6.1.jar;C:\kafka_\libs\metrics-core-2.2.0.jar;C:\kafka_\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_\libs\paranamer-2.8.jar;C:\kafka_\libs\plexus-utils-3.2.0.jar;C:\kafka_\libs\reflections-0.9.11.jar;C:\kafka_\libs\rocksdbjni-5.18.3.jar;C:\kafka_\libs\scala-library-2.12.8.jar;C:\kafka_\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_\libs\scala-reflect-2.12.8.jar;C:\kafka_\libs\slf4j-api-1.7.26.jar;C:\kafka_\libs\slf4j-log4j12-1.7.26.jar;C:\kafka_\libs\snappy-java-1.1.7.3.jar;C:\kafka_\libs\spotbugs-annotations-3.1.9.jar;C:\kafka_\libs\validation-api-2.0.1.Final.jar;C:\kafka_\libs\zkclient-0.11.jar;C:\kafka_\libs\zookeeper-3.4.14.jar;C:\kafka_\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,441] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_31\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Intel\iCLS Client\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Skype\Phone\;C:\Program Files (x86)\Microsoft SQL Server\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\apache-maven-3.6.0\bin;C:\Program Files\Git\cmd;C:\Program Files (x86)\MySQL\MySQL Fabric 1.5.3 & MySQL Utilities 1.5.3 1.5\;C:\Program Files (x86)\MySQL\MySQL Fabric 1.5.3 & MySQL Utilities 1.5.3 1.5\Doctrine extensions for PHP\;C:\Program Files (x86)\WinSCP\;C:\Users\Syarif_H657\Downloads\gradle-5.2.1\bin;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\MongoDB\Server\4.0\bin;C:\Go\bin;C:\Program Files\Java\jdk1.8.0_31\bin;;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\nodejs\;C:\Users\Syarif_H657\AppData\Local\Programs\Python\Python37-32\Scripts\;C:\Users\Syarif_H657\AppData\Local\Programs\Python\Python37-32\;C:\Users\Syarif_H657\AppData\Local\Microsoft\WindowsApps;C:\Program Files\JetBrains\IntelliJ IDEA 2018.3.4\bin;C:\Program Files\JetBrains\WebStorm 2018.3.5\bin;C:\Users\Syarif_H657\AppData\Local\Yarn\bin;C:\Program Files\JetBrains\GoLand 2019.1.3\bin;C:\Users\Syarif_H657\go\bin;C:\Users\Syarif_H657\AppData\Local\GitHubDesktop\bin;C:\Users\Syarif_H657\AppData\Local\Microsoft\WindowsApps;;f:\Atlassian\atlassian-plugin-sdk-8.0.16\bin;C:\Program Files\Haulmont\CUBA Studio 2019.1\bin;;C:\Users\Syarif_H657\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,445] INFO Client environment:java.io.tmpdir=C:\Users\SYARIF~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,446] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,446] INFO Client environment:os.name=Windows 8.1 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,447] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,448] INFO Client environment:os.version=6.3 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,449] INFO Client environment:user.name=Syarif_H657 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,450] INFO Client environment:user.home=C:\Users\Syarif_H657 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,451] INFO Client environment:user.dir=C:\kafka_\bin\windows (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,457] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2e4b8173 (org.apache.zookeeper.ZooKeeper)
[2020-02-27 09:22:31,511] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-27 09:22:31,516] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-02-27 09:22:31,520] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:49556 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-27 09:22:31,521] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-02-27 09:22:31,533] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:49556 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:31,540] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-02-27 09:22:31,578] INFO Established session 0x100476185150000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:49556 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-27 09:22:31,583] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100476185150000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-02-27 09:22:31,593] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-27 09:22:32,143] INFO Got user-level KeeperException when processing sessionid:0x100476185150000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:22:32,164] INFO Got user-level KeeperException when processing sessionid:0x100476185150000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:22:32,177] INFO Got user-level KeeperException when processing sessionid:0x100476185150000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:22:32,620] INFO Got user-level KeeperException when processing sessionid:0x100476185150000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:22:32,633] INFO Cluster ID = RPH0zCYbTHmc08cGy4uWZA (kafka.server.KafkaServer)
[2020-02-27 09:22:32,643] WARN No meta.properties file under dir c:\log\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-02-27 09:22:32,808] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = c:\log
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-27 09:22:32,830] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = c:\log
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-27 09:22:32,890] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-27 09:22:32,892] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-27 09:22:32,893] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-27 09:22:32,945] INFO Log directory c:\log not found, creating it. (kafka.log.LogManager)
[2020-02-27 09:22:32,963] INFO Loading logs. (kafka.log.LogManager)
[2020-02-27 09:22:32,978] INFO Logs loading complete in 15 ms. (kafka.log.LogManager)
[2020-02-27 09:22:33,010] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-02-27 09:22:33,017] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-02-27 09:22:33,692] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2020-02-27 09:22:33,754] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-02-27 09:22:33,758] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-02-27 09:22:33,810] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 09:22:33,812] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 09:22:33,813] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 09:22:33,815] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 09:22:33,840] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-02-27 09:22:33,878] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-02-27 09:22:33,942] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1582770153912,1582770153912,1,0,0,72136078208073728,188,0,24
 (kafka.zk.KafkaZkClient)
[2020-02-27 09:22:33,947] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2020-02-27 09:22:33,956] WARN No meta.properties file under dir c:\log\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-02-27 09:22:34,089] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 09:22:34,096] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 09:22:34,098] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-27 09:22:34,123] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-02-27 09:22:34,142] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:22:34,147] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:22:34,195] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 33 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:34,209] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-02-27 09:22:34,275] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-02-27 09:22:34,279] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-02-27 09:22:34,279] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-02-27 09:22:34,380] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-02-27 09:22:34,396] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-02-27 09:22:34,447] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-02-27 09:22:34,460] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2020-02-27 09:22:34,461] INFO Kafka startTimeMs: 1582770154398 (org.apache.kafka.common.utils.AppInfoParser)
[2020-02-27 09:22:34,442] INFO Got user-level KeeperException when processing sessionid:0x100476185150000 type:multi cxid:0x38 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:22:34,497] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-02-27 09:22:34,592] INFO Creating topic blog-creation with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-02-27 09:22:34,597] INFO Got user-level KeeperException when processing sessionid:0x100476185150000 type:setData cxid:0x40 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics/blog-creation Error:KeeperErrorCode = NoNode for /config/topics/blog-creation (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:22:34,633] INFO [KafkaApi-0] Auto creation of topic blog-creation with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-02-27 09:22:34,695] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-02-27 09:22:34,698] INFO Got user-level KeeperException when processing sessionid:0x100476185150000 type:setData cxid:0x4a zxid:0x21 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:22:34,714] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-02-27 09:22:34,792] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(blog-creation-0) (kafka.server.ReplicaFetcherManager)
[2020-02-27 09:22:35,282] INFO [Log partition=blog-creation-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:35,332] INFO [Log partition=blog-creation-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 420 ms (kafka.log.Log)
[2020-02-27 09:22:35,354] INFO Created log for partition blog-creation-0 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:35,356] INFO [Partition blog-creation-0 broker=0] No checkpointed highwatermark is found for partition blog-creation-0 (kafka.cluster.Partition)
[2020-02-27 09:22:35,360] INFO Replica loaded for partition blog-creation-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:35,372] INFO [Partition blog-creation-0 broker=0] blog-creation-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:35,688] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-02-27 09:22:35,748] INFO [Log partition=__consumer_offsets-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:35,757] INFO [Log partition=__consumer_offsets-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-02-27 09:22:35,760] INFO Created log for partition __consumer_offsets-0 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:35,763] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-02-27 09:22:35,764] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:35,766] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:35,792] INFO [Log partition=__consumer_offsets-29, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:35,796] INFO [Log partition=__consumer_offsets-29, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-27 09:22:35,797] INFO Created log for partition __consumer_offsets-29 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:35,798] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-02-27 09:22:35,799] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:35,802] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:35,828] INFO [Log partition=__consumer_offsets-48, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:35,831] INFO [Log partition=__consumer_offsets-48, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-27 09:22:35,833] INFO Created log for partition __consumer_offsets-48 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:35,834] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-02-27 09:22:35,835] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:35,838] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:35,857] INFO [Log partition=__consumer_offsets-10, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:35,859] INFO [Log partition=__consumer_offsets-10, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-27 09:22:35,861] INFO Created log for partition __consumer_offsets-10 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:35,862] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-02-27 09:22:35,863] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:35,865] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:35,892] INFO [Log partition=__consumer_offsets-45, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:35,895] INFO [Log partition=__consumer_offsets-45, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-27 09:22:35,896] INFO Created log for partition __consumer_offsets-45 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:35,897] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-02-27 09:22:35,899] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:35,902] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:35,926] INFO [Log partition=__consumer_offsets-26, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:35,929] INFO [Log partition=__consumer_offsets-26, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-27 09:22:35,931] INFO Created log for partition __consumer_offsets-26 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:35,933] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-02-27 09:22:35,935] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:35,938] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:35,958] INFO [Log partition=__consumer_offsets-7, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:35,963] INFO [Log partition=__consumer_offsets-7, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-02-27 09:22:35,965] INFO Created log for partition __consumer_offsets-7 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:35,968] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-02-27 09:22:35,970] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:35,972] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:35,996] INFO [Log partition=__consumer_offsets-42, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:36,002] INFO [Log partition=__consumer_offsets-42, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-02-27 09:22:36,006] INFO Created log for partition __consumer_offsets-42 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:36,010] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-02-27 09:22:36,011] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:36,013] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:36,046] INFO [Log partition=__consumer_offsets-4, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:36,049] INFO [Log partition=__consumer_offsets-4, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-27 09:22:36,051] INFO Created log for partition __consumer_offsets-4 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:36,053] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-02-27 09:22:36,054] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:36,055] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:36,071] INFO [Log partition=__consumer_offsets-23, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:36,074] INFO [Log partition=__consumer_offsets-23, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-27 09:22:36,075] INFO Created log for partition __consumer_offsets-23 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:36,076] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-02-27 09:22:36,077] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:36,078] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:36,110] INFO [Log partition=__consumer_offsets-1, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:36,115] INFO [Log partition=__consumer_offsets-1, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-02-27 09:22:36,122] INFO Created log for partition __consumer_offsets-1 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:36,132] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-02-27 09:22:36,144] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:36,155] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:36,193] INFO [Log partition=__consumer_offsets-20, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:36,198] INFO [Log partition=__consumer_offsets-20, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-27 09:22:36,209] INFO Created log for partition __consumer_offsets-20 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:36,211] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-02-27 09:22:36,215] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:36,221] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:36,276] INFO [Log partition=__consumer_offsets-39, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:36,281] INFO [Log partition=__consumer_offsets-39, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2020-02-27 09:22:36,289] INFO Created log for partition __consumer_offsets-39 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:36,292] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-02-27 09:22:36,294] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:36,295] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:36,379] INFO [Log partition=__consumer_offsets-17, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:36,389] INFO [Log partition=__consumer_offsets-17, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2020-02-27 09:22:36,393] INFO Created log for partition __consumer_offsets-17 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:36,398] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-02-27 09:22:36,409] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:36,415] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:36,576] INFO [Log partition=__consumer_offsets-36, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:36,582] INFO [Log partition=__consumer_offsets-36, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 95 ms (kafka.log.Log)
[2020-02-27 09:22:36,597] INFO Created log for partition __consumer_offsets-36 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:36,610] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-02-27 09:22:36,612] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:36,613] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:36,692] INFO [Log partition=__consumer_offsets-14, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:36,697] INFO [Log partition=__consumer_offsets-14, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-02-27 09:22:36,705] INFO Created log for partition __consumer_offsets-14 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:36,707] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-02-27 09:22:36,709] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:36,711] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:36,953] INFO [Log partition=__consumer_offsets-33, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:36,981] INFO [Log partition=__consumer_offsets-33, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 242 ms (kafka.log.Log)
[2020-02-27 09:22:37,007] INFO Created log for partition __consumer_offsets-33 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,021] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-02-27 09:22:37,031] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,042] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:37,106] INFO [Log partition=__consumer_offsets-49, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:37,110] INFO [Log partition=__consumer_offsets-49, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-27 09:22:37,111] INFO Created log for partition __consumer_offsets-49 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,112] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-02-27 09:22:37,113] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,114] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:37,139] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:37,142] INFO [Log partition=__consumer_offsets-11, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-27 09:22:37,145] INFO Created log for partition __consumer_offsets-11 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,147] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-02-27 09:22:37,147] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,148] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:37,179] INFO [Log partition=__consumer_offsets-30, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:37,188] INFO [Log partition=__consumer_offsets-30, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-27 09:22:37,194] INFO Created log for partition __consumer_offsets-30 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,196] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-02-27 09:22:37,198] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,242] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:37,375] INFO [Log partition=__consumer_offsets-46, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:37,379] INFO [Log partition=__consumer_offsets-46, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-02-27 09:22:37,381] INFO Created log for partition __consumer_offsets-46 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,386] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-02-27 09:22:37,388] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,389] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:37,412] INFO [Log partition=__consumer_offsets-27, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:37,415] INFO [Log partition=__consumer_offsets-27, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-27 09:22:37,417] INFO Created log for partition __consumer_offsets-27 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,420] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-02-27 09:22:37,420] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,422] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:37,454] INFO [Log partition=__consumer_offsets-8, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:37,458] INFO [Log partition=__consumer_offsets-8, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-02-27 09:22:37,461] INFO Created log for partition __consumer_offsets-8 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,462] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-02-27 09:22:37,463] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,465] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:37,484] INFO [Log partition=__consumer_offsets-24, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:37,489] INFO [Log partition=__consumer_offsets-24, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-27 09:22:37,490] INFO Created log for partition __consumer_offsets-24 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,492] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-02-27 09:22:37,493] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,494] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:37,514] INFO [Log partition=__consumer_offsets-43, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:37,519] INFO [Log partition=__consumer_offsets-43, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-27 09:22:37,520] INFO Created log for partition __consumer_offsets-43 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,521] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-02-27 09:22:37,522] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,523] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:37,549] INFO [Log partition=__consumer_offsets-5, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:37,554] INFO [Log partition=__consumer_offsets-5, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-27 09:22:37,555] INFO Created log for partition __consumer_offsets-5 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,556] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-02-27 09:22:37,557] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,558] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:37,582] INFO [Log partition=__consumer_offsets-21, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:37,587] INFO [Log partition=__consumer_offsets-21, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-27 09:22:37,588] INFO Created log for partition __consumer_offsets-21 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,589] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-02-27 09:22:37,589] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,591] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:37,631] INFO [Log partition=__consumer_offsets-2, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:37,634] INFO [Log partition=__consumer_offsets-2, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-27 09:22:37,635] INFO Created log for partition __consumer_offsets-2 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,636] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-02-27 09:22:37,637] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,638] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:37,793] INFO [Log partition=__consumer_offsets-40, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:37,796] INFO [Log partition=__consumer_offsets-40, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-27 09:22:37,797] INFO Created log for partition __consumer_offsets-40 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,798] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-02-27 09:22:37,799] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,800] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:37,850] INFO [Log partition=__consumer_offsets-37, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:37,853] INFO [Log partition=__consumer_offsets-37, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-27 09:22:37,854] INFO Created log for partition __consumer_offsets-37 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,855] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-02-27 09:22:37,856] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,857] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:37,888] INFO [Log partition=__consumer_offsets-18, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:37,892] INFO [Log partition=__consumer_offsets-18, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-27 09:22:37,893] INFO Created log for partition __consumer_offsets-18 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,894] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-02-27 09:22:37,895] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,896] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:37,937] INFO [Log partition=__consumer_offsets-34, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:37,941] INFO [Log partition=__consumer_offsets-34, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-27 09:22:37,943] INFO Created log for partition __consumer_offsets-34 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:37,944] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-02-27 09:22:37,946] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:37,969] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:38,063] INFO [Log partition=__consumer_offsets-15, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:38,075] INFO [Log partition=__consumer_offsets-15, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2020-02-27 09:22:38,078] INFO Created log for partition __consumer_offsets-15 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:38,086] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-02-27 09:22:38,089] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:38,093] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:38,169] INFO [Log partition=__consumer_offsets-12, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:38,176] INFO [Log partition=__consumer_offsets-12, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2020-02-27 09:22:38,181] INFO Created log for partition __consumer_offsets-12 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:38,188] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-02-27 09:22:38,190] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:38,192] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:38,262] INFO [Log partition=__consumer_offsets-31, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:38,272] INFO [Log partition=__consumer_offsets-31, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2020-02-27 09:22:38,278] INFO Created log for partition __consumer_offsets-31 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:38,280] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-02-27 09:22:38,281] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:38,287] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:38,357] INFO [Log partition=__consumer_offsets-9, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:38,362] INFO [Log partition=__consumer_offsets-9, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-02-27 09:22:38,365] INFO Created log for partition __consumer_offsets-9 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:38,372] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-02-27 09:22:38,375] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:38,390] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:38,459] INFO [Log partition=__consumer_offsets-47, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:38,468] INFO [Log partition=__consumer_offsets-47, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2020-02-27 09:22:38,472] INFO Created log for partition __consumer_offsets-47 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:38,474] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-02-27 09:22:38,476] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:38,479] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:38,544] INFO [Log partition=__consumer_offsets-19, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:38,553] INFO [Log partition=__consumer_offsets-19, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-02-27 09:22:38,557] INFO Created log for partition __consumer_offsets-19 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:38,560] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-02-27 09:22:38,561] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:38,565] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:38,644] INFO [Log partition=__consumer_offsets-28, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:38,649] INFO [Log partition=__consumer_offsets-28, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-02-27 09:22:38,655] INFO Created log for partition __consumer_offsets-28 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:38,658] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-02-27 09:22:38,659] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:38,661] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:38,705] INFO [Log partition=__consumer_offsets-38, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:38,721] INFO [Log partition=__consumer_offsets-38, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2020-02-27 09:22:38,726] INFO Created log for partition __consumer_offsets-38 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:38,731] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-02-27 09:22:38,732] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:38,736] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:38,774] INFO [Log partition=__consumer_offsets-35, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:38,780] INFO [Log partition=__consumer_offsets-35, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-02-27 09:22:38,788] INFO Created log for partition __consumer_offsets-35 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:38,791] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-02-27 09:22:38,794] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:38,796] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:38,856] INFO [Log partition=__consumer_offsets-44, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:38,862] INFO [Log partition=__consumer_offsets-44, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2020-02-27 09:22:38,864] INFO Created log for partition __consumer_offsets-44 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:38,869] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-02-27 09:22:38,871] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:38,873] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:38,931] INFO [Log partition=__consumer_offsets-6, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:38,938] INFO [Log partition=__consumer_offsets-6, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2020-02-27 09:22:38,954] INFO Created log for partition __consumer_offsets-6 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:38,960] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-02-27 09:22:38,963] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:38,968] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:39,072] INFO [Log partition=__consumer_offsets-25, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:39,081] INFO [Log partition=__consumer_offsets-25, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 73 ms (kafka.log.Log)
[2020-02-27 09:22:39,089] INFO Created log for partition __consumer_offsets-25 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:39,092] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-02-27 09:22:39,095] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:39,098] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:39,187] INFO [Log partition=__consumer_offsets-16, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:39,195] INFO [Log partition=__consumer_offsets-16, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2020-02-27 09:22:39,199] INFO Created log for partition __consumer_offsets-16 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:39,202] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-02-27 09:22:39,210] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:39,213] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:39,358] INFO [Log partition=__consumer_offsets-22, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:39,365] INFO [Log partition=__consumer_offsets-22, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 104 ms (kafka.log.Log)
[2020-02-27 09:22:39,373] INFO Created log for partition __consumer_offsets-22 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:39,376] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-02-27 09:22:39,381] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:39,387] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:39,462] INFO [Log partition=__consumer_offsets-41, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:39,472] INFO [Log partition=__consumer_offsets-41, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2020-02-27 09:22:39,475] INFO Created log for partition __consumer_offsets-41 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:39,479] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-02-27 09:22:39,481] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:39,485] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:39,607] INFO [Log partition=__consumer_offsets-32, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:39,613] INFO [Log partition=__consumer_offsets-32, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 90 ms (kafka.log.Log)
[2020-02-27 09:22:39,621] INFO Created log for partition __consumer_offsets-32 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:39,626] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-02-27 09:22:39,629] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:39,634] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:39,714] INFO [Log partition=__consumer_offsets-3, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:39,722] INFO [Log partition=__consumer_offsets-3, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 52 ms (kafka.log.Log)
[2020-02-27 09:22:39,725] INFO Created log for partition __consumer_offsets-3 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:39,729] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-02-27 09:22:39,731] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:39,738] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:39,824] INFO [Log partition=__consumer_offsets-13, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:39,830] INFO [Log partition=__consumer_offsets-13, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2020-02-27 09:22:39,838] INFO Created log for partition __consumer_offsets-13 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:39,841] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-02-27 09:22:39,844] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:39,847] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:39,875] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:39,947] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:39,969] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:39,979] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:39,989] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,013] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,014] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 67 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,021] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,026] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,028] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,041] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,029] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,045] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,054] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,050] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,073] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,069] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,077] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,078] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,097] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,093] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,106] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,109] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,106] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,112] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,114] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,120] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,114] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,145] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,128] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,209] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,174] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,243] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,239] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,267] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,260] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,276] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,277] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,285] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,280] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,305] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,293] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,318] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,313] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,353] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,325] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,374] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,370] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,431] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,413] INFO Creating topic blog-key with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-02-27 09:22:40,453] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,439] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,463] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,460] INFO Got user-level KeeperException when processing sessionid:0x100476185150000 type:setData cxid:0x192 zxid:0x8b txntype:-1 reqpath:n/a Error Path:/config/topics/blog-key Error:KeeperErrorCode = NoNode for /config/topics/blog-key (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:22:40,472] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,466] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,478] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,476] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,487] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,488] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,488] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,497] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,495] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,508] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,504] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,517] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,556] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,548] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 28 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,559] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,560] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,565] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,568] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,575] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,570] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,581] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,589] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,583] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,593] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,594] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,595] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,597] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,607] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,610] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,610] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,626] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,613] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,630] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,632] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,630] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,637] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,635] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,640] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,642] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,656] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,661] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,664] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(blog-key-0) (kafka.server.ReplicaFetcherManager)
[2020-02-27 09:22:40,670] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,674] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,676] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,679] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:22:40,698] INFO [Log partition=blog-key-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:40,706] INFO [Log partition=blog-key-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-02-27 09:22:40,708] INFO Created log for partition blog-key-0 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:40,714] INFO [Partition blog-key-0 broker=0] No checkpointed highwatermark is found for partition blog-key-0 (kafka.cluster.Partition)
[2020-02-27 09:22:40,720] INFO Replica loaded for partition blog-key-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:40,726] INFO [Partition blog-key-0 broker=0] blog-key-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:40,952] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.e79a2ad1-f9c4-41f1-b3e1-f752192a7777 in state PreparingRebalance with old generation 0 (__consumer_offsets-25) (reason: Adding new member consumer-2-a22c108f-1062-4fd6-941e-a5eb3171c2ab with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:22:41,035] INFO [GroupCoordinator 0]: Stabilized group anonymous.e79a2ad1-f9c4-41f1-b3e1-f752192a7777 generation 1 (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:22:41,081] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.e79a2ad1-f9c4-41f1-b3e1-f752192a7777 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:22:42,336] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.902a3e8a-5117-445a-97e0-f5ef1b15ecbc in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member consumer-2-91adbf49-1d68-4afb-98af-f313cbc8aabb with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:22:42,373] INFO [GroupCoordinator 0]: Stabilized group anonymous.902a3e8a-5117-445a-97e0-f5ef1b15ecbc generation 1 (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:22:42,390] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.902a3e8a-5117-445a-97e0-f5ef1b15ecbc for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:22:42,405] INFO Creating topic blog-notification with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-02-27 09:22:42,408] INFO Got user-level KeeperException when processing sessionid:0x100476185150000 type:setData cxid:0x1a2 zxid:0x91 txntype:-1 reqpath:n/a Error Path:/config/topics/blog-notification Error:KeeperErrorCode = NoNode for /config/topics/blog-notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:22:42,536] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(blog-notification-0) (kafka.server.ReplicaFetcherManager)
[2020-02-27 09:22:42,571] INFO [Log partition=blog-notification-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:42,575] INFO [Log partition=blog-notification-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-02-27 09:22:42,579] INFO Created log for partition blog-notification-0 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:42,596] INFO [Partition blog-notification-0 broker=0] No checkpointed highwatermark is found for partition blog-notification-0 (kafka.cluster.Partition)
[2020-02-27 09:22:42,606] INFO Replica loaded for partition blog-notification-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:42,609] INFO [Partition blog-notification-0 broker=0] blog-notification-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:42,842] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.734c8cab-71f9-45df-88bf-ad5e9d9541d6 in state PreparingRebalance with old generation 0 (__consumer_offsets-39) (reason: Adding new member consumer-4-e05b28ed-9715-4ef8-adb7-a3a22789c947 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:22:42,854] INFO [GroupCoordinator 0]: Stabilized group anonymous.734c8cab-71f9-45df-88bf-ad5e9d9541d6 generation 1 (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:22:42,869] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.734c8cab-71f9-45df-88bf-ad5e9d9541d6 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:22:42,913] INFO Creating topic blog-approval with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-02-27 09:22:42,917] INFO Got user-level KeeperException when processing sessionid:0x100476185150000 type:setData cxid:0x1ac zxid:0x97 txntype:-1 reqpath:n/a Error Path:/config/topics/blog-approval Error:KeeperErrorCode = NoNode for /config/topics/blog-approval (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 09:22:43,015] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(blog-approval-0) (kafka.server.ReplicaFetcherManager)
[2020-02-27 09:22:43,030] INFO [Log partition=blog-approval-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 09:22:43,040] INFO [Log partition=blog-approval-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-27 09:22:43,042] INFO Created log for partition blog-approval-0 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 09:22:43,045] INFO [Partition blog-approval-0 broker=0] No checkpointed highwatermark is found for partition blog-approval-0 (kafka.cluster.Partition)
[2020-02-27 09:22:43,046] INFO Replica loaded for partition blog-approval-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 09:22:43,050] INFO [Partition blog-approval-0 broker=0] blog-approval-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 09:22:43,272] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.6b9ead05-426c-4111-97ee-24e2ecff8610 in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-6-4cf41e78-cdd8-498c-a9fa-4402fcc50307 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:22:43,278] INFO [GroupCoordinator 0]: Stabilized group anonymous.6b9ead05-426c-4111-97ee-24e2ecff8610 generation 1 (__consumer_offsets-1) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:22:43,303] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.6b9ead05-426c-4111-97ee-24e2ecff8610 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:32:34,213] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 18 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:42:34,166] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 09:46:44,332] INFO [GroupCoordinator 0]: Member consumer-2-91adbf49-1d68-4afb-98af-f313cbc8aabb in group anonymous.902a3e8a-5117-445a-97e0-f5ef1b15ecbc has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:46:44,334] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.902a3e8a-5117-445a-97e0-f5ef1b15ecbc in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: removing member consumer-2-91adbf49-1d68-4afb-98af-f313cbc8aabb on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:46:44,338] INFO [GroupCoordinator 0]: Group anonymous.902a3e8a-5117-445a-97e0-f5ef1b15ecbc with generation 2 is now empty (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:46:44,368] INFO [GroupCoordinator 0]: Member consumer-4-e05b28ed-9715-4ef8-adb7-a3a22789c947 in group anonymous.734c8cab-71f9-45df-88bf-ad5e9d9541d6 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:46:44,372] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.734c8cab-71f9-45df-88bf-ad5e9d9541d6 in state PreparingRebalance with old generation 1 (__consumer_offsets-39) (reason: removing member consumer-4-e05b28ed-9715-4ef8-adb7-a3a22789c947 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:46:44,376] INFO [GroupCoordinator 0]: Group anonymous.734c8cab-71f9-45df-88bf-ad5e9d9541d6 with generation 2 is now empty (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:46:44,446] INFO [GroupCoordinator 0]: Member consumer-6-4cf41e78-cdd8-498c-a9fa-4402fcc50307 in group anonymous.6b9ead05-426c-4111-97ee-24e2ecff8610 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:46:44,448] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.6b9ead05-426c-4111-97ee-24e2ecff8610 in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: removing member consumer-6-4cf41e78-cdd8-498c-a9fa-4402fcc50307 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:46:44,450] INFO [GroupCoordinator 0]: Group anonymous.6b9ead05-426c-4111-97ee-24e2ecff8610 with generation 2 is now empty (__consumer_offsets-1) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:48:31,241] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.a7968680-254b-4e45-ad46-d2ee4c8506f1 in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member consumer-2-26a61784-4059-4838-bc5b-ae896f878ad6 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:48:31,254] INFO [GroupCoordinator 0]: Stabilized group anonymous.a7968680-254b-4e45-ad46-d2ee4c8506f1 generation 1 (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:48:31,271] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.a7968680-254b-4e45-ad46-d2ee4c8506f1 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:48:31,613] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.a9b936b3-a1bf-45d7-9568-004ae9597e21 in state PreparingRebalance with old generation 0 (__consumer_offsets-34) (reason: Adding new member consumer-4-41e1b64b-f88a-4f4c-b8e2-f87df0f3b3c3 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:48:31,625] INFO [GroupCoordinator 0]: Stabilized group anonymous.a9b936b3-a1bf-45d7-9568-004ae9597e21 generation 1 (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:48:31,647] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.a9b936b3-a1bf-45d7-9568-004ae9597e21 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:48:32,028] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.c2a5f8fa-a69a-405e-a659-6a31fa1616e3 in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member consumer-6-a2f4e12b-a3c0-455b-847d-3e55c7462160 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:48:32,037] INFO [GroupCoordinator 0]: Stabilized group anonymous.c2a5f8fa-a69a-405e-a659-6a31fa1616e3 generation 1 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:48:32,041] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.c2a5f8fa-a69a-405e-a659-6a31fa1616e3 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:50:19,274] INFO [GroupCoordinator 0]: Member consumer-2-26a61784-4059-4838-bc5b-ae896f878ad6 in group anonymous.a7968680-254b-4e45-ad46-d2ee4c8506f1 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:50:19,281] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.a7968680-254b-4e45-ad46-d2ee4c8506f1 in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: removing member consumer-2-26a61784-4059-4838-bc5b-ae896f878ad6 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:50:19,283] INFO [GroupCoordinator 0]: Group anonymous.a7968680-254b-4e45-ad46-d2ee4c8506f1 with generation 2 is now empty (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:50:19,312] INFO [GroupCoordinator 0]: Member consumer-4-41e1b64b-f88a-4f4c-b8e2-f87df0f3b3c3 in group anonymous.a9b936b3-a1bf-45d7-9568-004ae9597e21 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:50:19,314] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.a9b936b3-a1bf-45d7-9568-004ae9597e21 in state PreparingRebalance with old generation 1 (__consumer_offsets-34) (reason: removing member consumer-4-41e1b64b-f88a-4f4c-b8e2-f87df0f3b3c3 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:50:19,316] INFO [GroupCoordinator 0]: Group anonymous.a9b936b3-a1bf-45d7-9568-004ae9597e21 with generation 2 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:50:19,354] INFO [GroupCoordinator 0]: Member consumer-6-a2f4e12b-a3c0-455b-847d-3e55c7462160 in group anonymous.c2a5f8fa-a69a-405e-a659-6a31fa1616e3 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:50:19,356] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.c2a5f8fa-a69a-405e-a659-6a31fa1616e3 in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: removing member consumer-6-a2f4e12b-a3c0-455b-847d-3e55c7462160 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:50:19,364] INFO [GroupCoordinator 0]: Group anonymous.c2a5f8fa-a69a-405e-a659-6a31fa1616e3 with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 09:52:34,213] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 10:02:34,227] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 10:10:22,336] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.225277f7-b3e2-44de-bc85-e4d55adcaa45 in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member consumer-2-43f0c08a-691a-4171-acdd-c0ac855d0563 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:22,349] INFO [GroupCoordinator 0]: Stabilized group anonymous.225277f7-b3e2-44de-bc85-e4d55adcaa45 generation 1 (__consumer_offsets-4) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:22,362] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.225277f7-b3e2-44de-bc85-e4d55adcaa45 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:22,559] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.e80786ed-1e08-4ff0-a701-d76ed2bbdcb3 in state PreparingRebalance with old generation 0 (__consumer_offsets-29) (reason: Adding new member consumer-4-5fac5958-c22b-48c2-a88d-3d06047f4562 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:22,569] INFO [GroupCoordinator 0]: Stabilized group anonymous.e80786ed-1e08-4ff0-a701-d76ed2bbdcb3 generation 1 (__consumer_offsets-29) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:22,573] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.e80786ed-1e08-4ff0-a701-d76ed2bbdcb3 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:22,803] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.eae50ff5-28bf-4ad1-85c7-99ef3b19e613 in state PreparingRebalance with old generation 0 (__consumer_offsets-18) (reason: Adding new member consumer-6-6da61ecd-eb53-435f-9316-4a41daba7f95 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:22,809] INFO [GroupCoordinator 0]: Stabilized group anonymous.eae50ff5-28bf-4ad1-85c7-99ef3b19e613 generation 1 (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:22,816] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.eae50ff5-28bf-4ad1-85c7-99ef3b19e613 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:47,493] INFO [GroupCoordinator 0]: Member consumer-2-43f0c08a-691a-4171-acdd-c0ac855d0563 in group anonymous.225277f7-b3e2-44de-bc85-e4d55adcaa45 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:47,499] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.225277f7-b3e2-44de-bc85-e4d55adcaa45 in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: removing member consumer-2-43f0c08a-691a-4171-acdd-c0ac855d0563 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:47,502] INFO [GroupCoordinator 0]: Group anonymous.225277f7-b3e2-44de-bc85-e4d55adcaa45 with generation 2 is now empty (__consumer_offsets-4) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:47,537] INFO [GroupCoordinator 0]: Member consumer-4-5fac5958-c22b-48c2-a88d-3d06047f4562 in group anonymous.e80786ed-1e08-4ff0-a701-d76ed2bbdcb3 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:47,539] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.e80786ed-1e08-4ff0-a701-d76ed2bbdcb3 in state PreparingRebalance with old generation 1 (__consumer_offsets-29) (reason: removing member consumer-4-5fac5958-c22b-48c2-a88d-3d06047f4562 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:47,541] INFO [GroupCoordinator 0]: Group anonymous.e80786ed-1e08-4ff0-a701-d76ed2bbdcb3 with generation 2 is now empty (__consumer_offsets-29) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:47,559] INFO [GroupCoordinator 0]: Member consumer-6-6da61ecd-eb53-435f-9316-4a41daba7f95 in group anonymous.eae50ff5-28bf-4ad1-85c7-99ef3b19e613 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:47,561] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.eae50ff5-28bf-4ad1-85c7-99ef3b19e613 in state PreparingRebalance with old generation 1 (__consumer_offsets-18) (reason: removing member consumer-6-6da61ecd-eb53-435f-9316-4a41daba7f95 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:10:47,564] INFO [GroupCoordinator 0]: Group anonymous.eae50ff5-28bf-4ad1-85c7-99ef3b19e613 with generation 2 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:12:34,229] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 10:17:00,398] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.29d4824f-5604-4e6c-98c7-e6b0b941ce18 in state PreparingRebalance with old generation 0 (__consumer_offsets-32) (reason: Adding new member consumer-2-0c7d2447-bf48-4afa-a55e-79835a3ce010 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:17:00,448] INFO [GroupCoordinator 0]: Stabilized group anonymous.29d4824f-5604-4e6c-98c7-e6b0b941ce18 generation 1 (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:17:00,460] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.29d4824f-5604-4e6c-98c7-e6b0b941ce18 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:17:00,681] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.6ecc806f-fe97-4f74-9133-c9568d05cba6 in state PreparingRebalance with old generation 0 (__consumer_offsets-34) (reason: Adding new member consumer-4-4b46f43d-b45e-4188-9d9f-7a9c18a67f80 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:17:00,691] INFO [GroupCoordinator 0]: Stabilized group anonymous.6ecc806f-fe97-4f74-9133-c9568d05cba6 generation 1 (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:17:00,724] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.6ecc806f-fe97-4f74-9133-c9568d05cba6 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:17:00,865] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.d0db0e53-65cf-4b37-9faf-ab73de230f08 in state PreparingRebalance with old generation 0 (__consumer_offsets-7) (reason: Adding new member consumer-6-ddd18fd7-f66d-43ac-bdef-7932c6e8608a with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:17:00,873] INFO [GroupCoordinator 0]: Stabilized group anonymous.d0db0e53-65cf-4b37-9faf-ab73de230f08 generation 1 (__consumer_offsets-7) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:17:00,877] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.d0db0e53-65cf-4b37-9faf-ab73de230f08 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:19:30,522] INFO [GroupCoordinator 0]: Member consumer-2-0c7d2447-bf48-4afa-a55e-79835a3ce010 in group anonymous.29d4824f-5604-4e6c-98c7-e6b0b941ce18 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:19:30,522] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.29d4824f-5604-4e6c-98c7-e6b0b941ce18 in state PreparingRebalance with old generation 1 (__consumer_offsets-32) (reason: removing member consumer-2-0c7d2447-bf48-4afa-a55e-79835a3ce010 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:19:30,532] INFO [GroupCoordinator 0]: Group anonymous.29d4824f-5604-4e6c-98c7-e6b0b941ce18 with generation 2 is now empty (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:19:30,562] INFO [GroupCoordinator 0]: Member consumer-4-4b46f43d-b45e-4188-9d9f-7a9c18a67f80 in group anonymous.6ecc806f-fe97-4f74-9133-c9568d05cba6 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:19:30,563] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.6ecc806f-fe97-4f74-9133-c9568d05cba6 in state PreparingRebalance with old generation 1 (__consumer_offsets-34) (reason: removing member consumer-4-4b46f43d-b45e-4188-9d9f-7a9c18a67f80 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:19:30,570] INFO [GroupCoordinator 0]: Group anonymous.6ecc806f-fe97-4f74-9133-c9568d05cba6 with generation 2 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:19:30,585] INFO [GroupCoordinator 0]: Member consumer-6-ddd18fd7-f66d-43ac-bdef-7932c6e8608a in group anonymous.d0db0e53-65cf-4b37-9faf-ab73de230f08 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:19:30,586] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.d0db0e53-65cf-4b37-9faf-ab73de230f08 in state PreparingRebalance with old generation 1 (__consumer_offsets-7) (reason: removing member consumer-6-ddd18fd7-f66d-43ac-bdef-7932c6e8608a on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:19:30,589] INFO [GroupCoordinator 0]: Group anonymous.d0db0e53-65cf-4b37-9faf-ab73de230f08 with generation 2 is now empty (__consumer_offsets-7) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:20:42,439] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.0e9a8e14-bcfc-415d-bbef-0d2a3ae0797b in state PreparingRebalance with old generation 0 (__consumer_offsets-38) (reason: Adding new member consumer-2-c3aaa89c-f3ab-448b-ac9d-e5f71fe060a3 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:20:42,441] INFO [GroupCoordinator 0]: Stabilized group anonymous.0e9a8e14-bcfc-415d-bbef-0d2a3ae0797b generation 1 (__consumer_offsets-38) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:20:42,457] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.0e9a8e14-bcfc-415d-bbef-0d2a3ae0797b for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:20:42,859] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.83b31959-601e-41b4-a4ea-8ff8a548726e in state PreparingRebalance with old generation 0 (__consumer_offsets-9) (reason: Adding new member consumer-4-e2ce9391-94c6-4377-81b7-b8f1735fca81 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:20:42,890] INFO [GroupCoordinator 0]: Stabilized group anonymous.83b31959-601e-41b4-a4ea-8ff8a548726e generation 1 (__consumer_offsets-9) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:20:42,897] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.83b31959-601e-41b4-a4ea-8ff8a548726e for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:20:43,079] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.d337c57f-d507-4707-9056-2902826a1263 in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member consumer-6-f55d179c-e87c-434c-a497-4bc9c6d73dbf with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:20:43,085] INFO [GroupCoordinator 0]: Stabilized group anonymous.d337c57f-d507-4707-9056-2902826a1263 generation 1 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:20:43,089] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.d337c57f-d507-4707-9056-2902826a1263 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:22:34,245] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 10:32:34,254] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 10:42:34,279] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 10:49:04,693] INFO [GroupCoordinator 0]: Member consumer-2-c3aaa89c-f3ab-448b-ac9d-e5f71fe060a3 in group anonymous.0e9a8e14-bcfc-415d-bbef-0d2a3ae0797b has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:49:04,698] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.0e9a8e14-bcfc-415d-bbef-0d2a3ae0797b in state PreparingRebalance with old generation 1 (__consumer_offsets-38) (reason: removing member consumer-2-c3aaa89c-f3ab-448b-ac9d-e5f71fe060a3 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:49:04,700] INFO [GroupCoordinator 0]: Group anonymous.0e9a8e14-bcfc-415d-bbef-0d2a3ae0797b with generation 2 is now empty (__consumer_offsets-38) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:49:04,735] INFO [GroupCoordinator 0]: Member consumer-4-e2ce9391-94c6-4377-81b7-b8f1735fca81 in group anonymous.83b31959-601e-41b4-a4ea-8ff8a548726e has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:49:04,742] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.83b31959-601e-41b4-a4ea-8ff8a548726e in state PreparingRebalance with old generation 1 (__consumer_offsets-9) (reason: removing member consumer-4-e2ce9391-94c6-4377-81b7-b8f1735fca81 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:49:04,749] INFO [GroupCoordinator 0]: Group anonymous.83b31959-601e-41b4-a4ea-8ff8a548726e with generation 2 is now empty (__consumer_offsets-9) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:49:04,767] INFO [GroupCoordinator 0]: Member consumer-6-f55d179c-e87c-434c-a497-4bc9c6d73dbf in group anonymous.d337c57f-d507-4707-9056-2902826a1263 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:49:04,770] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.d337c57f-d507-4707-9056-2902826a1263 in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: removing member consumer-6-f55d179c-e87c-434c-a497-4bc9c6d73dbf on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:49:04,771] INFO [GroupCoordinator 0]: Group anonymous.d337c57f-d507-4707-9056-2902826a1263 with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:50:28,448] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.dbf2ce65-d275-4d5e-a900-7a129f91fb1d in state PreparingRebalance with old generation 0 (__consumer_offsets-7) (reason: Adding new member consumer-2-b02e860c-72dd-4e9a-b048-7ce46a33b328 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:50:28,460] INFO [GroupCoordinator 0]: Stabilized group anonymous.dbf2ce65-d275-4d5e-a900-7a129f91fb1d generation 1 (__consumer_offsets-7) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:50:28,480] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.dbf2ce65-d275-4d5e-a900-7a129f91fb1d for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:50:28,671] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.04bd6658-058e-4bb3-8be8-8758a9c648d4 in state PreparingRebalance with old generation 0 (__consumer_offsets-29) (reason: Adding new member consumer-4-6ae92ea4-5e7e-43dc-a07b-057041b2b3ec with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:50:28,675] INFO [GroupCoordinator 0]: Stabilized group anonymous.04bd6658-058e-4bb3-8be8-8758a9c648d4 generation 1 (__consumer_offsets-29) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:50:28,681] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.04bd6658-058e-4bb3-8be8-8758a9c648d4 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:50:28,874] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.27503251-3c16-4b99-9abb-43ecfc027738 in state PreparingRebalance with old generation 0 (__consumer_offsets-16) (reason: Adding new member consumer-6-8e2b20a8-f971-4afa-90eb-b0b4e116ea95 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:50:28,882] INFO [GroupCoordinator 0]: Stabilized group anonymous.27503251-3c16-4b99-9abb-43ecfc027738 generation 1 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:50:28,892] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.27503251-3c16-4b99-9abb-43ecfc027738 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 10:52:34,301] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 11:02:34,315] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 11:12:34,317] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 11:22:34,330] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 11:32:34,354] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 11:42:34,374] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 11:52:34,389] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 12:02:34,406] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 12:12:34,414] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 12:22:34,421] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 12:32:34,432] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 12:42:34,458] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 12:46:10,888] INFO [GroupCoordinator 0]: Member consumer-2-b02e860c-72dd-4e9a-b048-7ce46a33b328 in group anonymous.dbf2ce65-d275-4d5e-a900-7a129f91fb1d has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:46:10,898] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.dbf2ce65-d275-4d5e-a900-7a129f91fb1d in state PreparingRebalance with old generation 1 (__consumer_offsets-7) (reason: removing member consumer-2-b02e860c-72dd-4e9a-b048-7ce46a33b328 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:46:10,900] INFO [GroupCoordinator 0]: Group anonymous.dbf2ce65-d275-4d5e-a900-7a129f91fb1d with generation 2 is now empty (__consumer_offsets-7) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:46:10,938] INFO [GroupCoordinator 0]: Member consumer-4-6ae92ea4-5e7e-43dc-a07b-057041b2b3ec in group anonymous.04bd6658-058e-4bb3-8be8-8758a9c648d4 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:46:10,939] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.04bd6658-058e-4bb3-8be8-8758a9c648d4 in state PreparingRebalance with old generation 1 (__consumer_offsets-29) (reason: removing member consumer-4-6ae92ea4-5e7e-43dc-a07b-057041b2b3ec on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:46:10,946] INFO [GroupCoordinator 0]: Group anonymous.04bd6658-058e-4bb3-8be8-8758a9c648d4 with generation 2 is now empty (__consumer_offsets-29) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:46:10,959] INFO [GroupCoordinator 0]: Member consumer-6-8e2b20a8-f971-4afa-90eb-b0b4e116ea95 in group anonymous.27503251-3c16-4b99-9abb-43ecfc027738 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:46:10,960] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.27503251-3c16-4b99-9abb-43ecfc027738 in state PreparingRebalance with old generation 1 (__consumer_offsets-16) (reason: removing member consumer-6-8e2b20a8-f971-4afa-90eb-b0b4e116ea95 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:46:10,961] INFO [GroupCoordinator 0]: Group anonymous.27503251-3c16-4b99-9abb-43ecfc027738 with generation 2 is now empty (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:47:13,072] INFO [GroupCoordinator 0]: Member consumer-2-a22c108f-1062-4fd6-941e-a5eb3171c2ab in group anonymous.e79a2ad1-f9c4-41f1-b3e1-f752192a7777 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:47:13,073] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.e79a2ad1-f9c4-41f1-b3e1-f752192a7777 in state PreparingRebalance with old generation 1 (__consumer_offsets-25) (reason: removing member consumer-2-a22c108f-1062-4fd6-941e-a5eb3171c2ab on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:47:13,075] INFO [GroupCoordinator 0]: Group anonymous.e79a2ad1-f9c4-41f1-b3e1-f752192a7777 with generation 2 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:48:02,681] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.1fce29cb-9328-4d98-a683-fdbb75732a69 in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-2-e670eba3-605a-49a3-bfa1-f125142cb9af with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:48:02,690] INFO [GroupCoordinator 0]: Stabilized group anonymous.1fce29cb-9328-4d98-a683-fdbb75732a69 generation 1 (__consumer_offsets-1) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:48:02,702] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.1fce29cb-9328-4d98-a683-fdbb75732a69 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:48:02,909] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.abcd9b9c-d064-4e7b-81d0-8b042d938864 in state PreparingRebalance with old generation 0 (__consumer_offsets-5) (reason: Adding new member consumer-4-7ac5599c-b087-4988-9aff-be9b759df842 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:48:02,919] INFO [GroupCoordinator 0]: Stabilized group anonymous.abcd9b9c-d064-4e7b-81d0-8b042d938864 generation 1 (__consumer_offsets-5) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:48:02,929] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.abcd9b9c-d064-4e7b-81d0-8b042d938864 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:48:03,456] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.eebfc97c-f094-433b-ac4b-0796120bc0b7 in state PreparingRebalance with old generation 0 (__consumer_offsets-17) (reason: Adding new member consumer-6-b4c38ed1-1ab7-4f2a-bf15-90931a69d7ec with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:48:03,465] INFO [GroupCoordinator 0]: Stabilized group anonymous.eebfc97c-f094-433b-ac4b-0796120bc0b7 generation 1 (__consumer_offsets-17) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:48:03,470] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.eebfc97c-f094-433b-ac4b-0796120bc0b7 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:52:34,473] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 12:56:08,448] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.96637902-5db7-478f-8fcc-dce3f3072324 in state PreparingRebalance with old generation 0 (__consumer_offsets-34) (reason: Adding new member consumer-2-f0ad542c-58fe-4281-ad75-719362ba45ca with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:56:08,449] INFO [GroupCoordinator 0]: Stabilized group anonymous.96637902-5db7-478f-8fcc-dce3f3072324 generation 1 (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 12:56:08,463] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.96637902-5db7-478f-8fcc-dce3f3072324 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:00:46,283] INFO [GroupCoordinator 0]: Member consumer-2-f0ad542c-58fe-4281-ad75-719362ba45ca in group anonymous.96637902-5db7-478f-8fcc-dce3f3072324 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:00:46,302] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.96637902-5db7-478f-8fcc-dce3f3072324 in state PreparingRebalance with old generation 1 (__consumer_offsets-34) (reason: removing member consumer-2-f0ad542c-58fe-4281-ad75-719362ba45ca on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:00:46,306] INFO [GroupCoordinator 0]: Group anonymous.96637902-5db7-478f-8fcc-dce3f3072324 with generation 2 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:02:02,382] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.201d638c-1974-4d7e-82ac-fbba82f82094 in state PreparingRebalance with old generation 0 (__consumer_offsets-21) (reason: Adding new member consumer-2-7f86d48e-c75d-4487-b548-ad5bb4d0a528 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:02:02,394] INFO [GroupCoordinator 0]: Stabilized group anonymous.201d638c-1974-4d7e-82ac-fbba82f82094 generation 1 (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:02:02,409] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.201d638c-1974-4d7e-82ac-fbba82f82094 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:02:34,487] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 13:12:34,486] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 13:22:34,488] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 13:22:56,313] INFO [GroupCoordinator 0]: Member consumer-2-7f86d48e-c75d-4487-b548-ad5bb4d0a528 in group anonymous.201d638c-1974-4d7e-82ac-fbba82f82094 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:22:56,314] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.201d638c-1974-4d7e-82ac-fbba82f82094 in state PreparingRebalance with old generation 1 (__consumer_offsets-21) (reason: removing member consumer-2-7f86d48e-c75d-4487-b548-ad5bb4d0a528 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:22:56,322] INFO [GroupCoordinator 0]: Group anonymous.201d638c-1974-4d7e-82ac-fbba82f82094 with generation 2 is now empty (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:24:24,512] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.f5b8c032-ff87-41ba-9f34-32c451e4a504 in state PreparingRebalance with old generation 0 (__consumer_offsets-24) (reason: Adding new member consumer-2-88c45dd6-db60-410c-93a6-d3096f1ae955 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:24:24,524] INFO [GroupCoordinator 0]: Stabilized group anonymous.f5b8c032-ff87-41ba-9f34-32c451e4a504 generation 1 (__consumer_offsets-24) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:24:24,538] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.f5b8c032-ff87-41ba-9f34-32c451e4a504 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:32:34,492] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 13:40:53,968] INFO [GroupCoordinator 0]: Member consumer-2-88c45dd6-db60-410c-93a6-d3096f1ae955 in group anonymous.f5b8c032-ff87-41ba-9f34-32c451e4a504 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:40:53,984] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.f5b8c032-ff87-41ba-9f34-32c451e4a504 in state PreparingRebalance with old generation 1 (__consumer_offsets-24) (reason: removing member consumer-2-88c45dd6-db60-410c-93a6-d3096f1ae955 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:40:53,987] INFO [GroupCoordinator 0]: Group anonymous.f5b8c032-ff87-41ba-9f34-32c451e4a504 with generation 2 is now empty (__consumer_offsets-24) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:42:13,913] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.f177ce83-78d3-42cf-abe3-9e14e601fdc2 in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member consumer-2-72c39cea-1e40-490f-bdaa-f0e49317701e with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:42:13,920] INFO [GroupCoordinator 0]: Stabilized group anonymous.f177ce83-78d3-42cf-abe3-9e14e601fdc2 generation 1 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:42:13,935] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.f177ce83-78d3-42cf-abe3-9e14e601fdc2 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 13:42:34,516] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 13:52:34,568] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 14:00:07,587] INFO [GroupCoordinator 0]: Member consumer-2-72c39cea-1e40-490f-bdaa-f0e49317701e in group anonymous.f177ce83-78d3-42cf-abe3-9e14e601fdc2 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 14:00:07,610] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.f177ce83-78d3-42cf-abe3-9e14e601fdc2 in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: removing member consumer-2-72c39cea-1e40-490f-bdaa-f0e49317701e on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 14:00:07,615] INFO [GroupCoordinator 0]: Group anonymous.f177ce83-78d3-42cf-abe3-9e14e601fdc2 with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 14:02:34,593] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 14:07:05,887] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.25e6aa5b-0ee0-41ec-a518-823ed3c6ca4e in state PreparingRebalance with old generation 0 (__consumer_offsets-33) (reason: Adding new member consumer-2-7eb602e4-8e7c-40e8-95d3-4fd7a58ccdba with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 14:07:05,893] INFO [GroupCoordinator 0]: Stabilized group anonymous.25e6aa5b-0ee0-41ec-a518-823ed3c6ca4e generation 1 (__consumer_offsets-33) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 14:07:05,908] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.25e6aa5b-0ee0-41ec-a518-823ed3c6ca4e for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 14:12:34,605] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 14:22:34,613] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 14:32:34,618] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 14:42:19,739] INFO [GroupCoordinator 0]: Member consumer-2-7eb602e4-8e7c-40e8-95d3-4fd7a58ccdba in group anonymous.25e6aa5b-0ee0-41ec-a518-823ed3c6ca4e has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 14:42:19,743] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.25e6aa5b-0ee0-41ec-a518-823ed3c6ca4e in state PreparingRebalance with old generation 1 (__consumer_offsets-33) (reason: removing member consumer-2-7eb602e4-8e7c-40e8-95d3-4fd7a58ccdba on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 14:42:19,747] INFO [GroupCoordinator 0]: Group anonymous.25e6aa5b-0ee0-41ec-a518-823ed3c6ca4e with generation 2 is now empty (__consumer_offsets-33) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 14:42:34,620] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 14:44:06,780] INFO [GroupCoordinator 0]: Preparing to rebalance group anonymous.770b7f07-480c-4de3-b08b-24ab93553209 in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member consumer-2-65f10aa2-0720-4e3f-8788-00388e0be9fc with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 14:44:06,798] INFO [GroupCoordinator 0]: Stabilized group anonymous.770b7f07-480c-4de3-b08b-24ab93553209 generation 1 (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 14:44:06,814] INFO [GroupCoordinator 0]: Assignment received from leader for group anonymous.770b7f07-480c-4de3-b08b-24ab93553209 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-27 14:52:34,646] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 15:02:34,675] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 15:12:34,693] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 15:22:34,699] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 15:32:34,704] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 15:42:34,707] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 15:44:40,712] INFO Creating topic blog-number-per-category with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-02-27 15:44:40,723] INFO Got user-level KeeperException when processing sessionid:0x100476185150000 type:setData cxid:0x1b6 zxid:0x9d txntype:-1 reqpath:n/a Error Path:/config/topics/blog-number-per-category Error:KeeperErrorCode = NoNode for /config/topics/blog-number-per-category (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-27 15:44:40,804] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(blog-number-per-category-0) (kafka.server.ReplicaFetcherManager)
[2020-02-27 15:44:40,821] INFO [Log partition=blog-number-per-category-0, dir=c:\log] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-27 15:44:40,824] INFO [Log partition=blog-number-per-category-0, dir=c:\log] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-02-27 15:44:40,825] INFO Created log for partition blog-number-per-category-0 in c:\log with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-27 15:44:40,829] INFO [Partition blog-number-per-category-0 broker=0] No checkpointed highwatermark is found for partition blog-number-per-category-0 (kafka.cluster.Partition)
[2020-02-27 15:44:40,830] INFO Replica loaded for partition blog-number-per-category-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-27 15:44:40,832] INFO [Partition blog-number-per-category-0 broker=0] blog-number-per-category-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-27 15:52:34,710] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 16:02:34,739] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-27 16:11:37,392] WARN Exception causing close of session 0x100476185150000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-27 16:11:37,408] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:49556 which had sessionid 0x100476185150000 (org.apache.zookeeper.server.NIOServerCnxn)
